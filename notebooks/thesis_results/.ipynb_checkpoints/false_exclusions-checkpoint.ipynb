{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9ec14a-ee5b-4572-ba67-4a239f003571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import swyft\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import importlib\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device_notebook = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import wandb\n",
    "import copy\n",
    "from torch.multiprocessing import Pool\n",
    "torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "torch.set_num_threads(28)\n",
    "import itertools\n",
    "import subprocess\n",
    "from tqdm.auto import tqdm\n",
    "sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n",
    "from explim_functions import find_false_exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "becc7ee8-c272-4b84-ba2f-2e11bc30d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"ALPs_with_SWYFT\"\n",
    "thesis_figs = os.getcwd().split(main_dir)[0]+\"/\"+main_dir+\"/thesis_figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75fd7ce4-6c3c-40dd-8888-7e153efd0893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "names = ['flare0_agnostic','flare0_semi_informed']\n",
    "colors_priors = ['r','#FFA500','y','g','b', ]\n",
    "\n",
    "priors = {}\n",
    "for ip, name in enumerate(names):\n",
    "\n",
    "    priors[name] = {'name': name}\n",
    "\n",
    "    priors[name]['results_path'] = '/home/gertwk/ALPs_with_SWYFT/cluster_runs/analysis_results/'+name\n",
    "    \n",
    "    priors[name]['store_path'] = priors[name]['results_path']+\"/sim_output/store\"\n",
    "\n",
    "    priors[name]['config_vars'] = priors[name]['results_path'] +'/config_variables.pickle'\n",
    "\n",
    "    priors[name]['config_phys'] = priors[name]['results_path'] +'/physics_variables.pickle'\n",
    "    \n",
    "    priors[name]['truncation_record'] = priors[name]['results_path'] +'/truncation_record.pickle'\n",
    "\n",
    "    removed_ALP_sim=0\n",
    "    try:\n",
    "        sys.path.remove('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n",
    "        removed_ALP_sim=1\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        del sys.modules['ALP_quick_sim']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    sys.path.append(priors[name]['results_path'])\n",
    "    import param_function\n",
    "    import ALP_quick_sim\n",
    "    with open(priors[name]['config_vars'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    with open(priors[name]['config_phys'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    with open(priors[name]['truncation_record'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    sys.path.remove(priors[name]['results_path'])\n",
    "    sys.path.append(priors[name]['results_path']+'/train_output/net')\n",
    "    import network\n",
    "    sys.path.remove(priors[name]['results_path']+'/train_output/net')\n",
    "    \n",
    "    count = 0\n",
    "    for combo in itertools.product(*priors[name]['hyperparams'].values()):\n",
    "        if count == priors[name]['which_grid_point']:\n",
    "            hyperparams_point = {}\n",
    "            for i, key in enumerate(priors[name]['hyperparams'].keys()):\n",
    "                hyperparams_point[key]=combo[i]\n",
    "        count +=1\n",
    "        \n",
    "    priors[name]['net_path'] = (priors[name]['results_path'] + '/train_output/net/trained_network_round_'\n",
    "                                +str(priors[name]['which_truncation'])+'_gridpoint_'+str(priors[name]['which_grid_point'])+'.pt')\n",
    "\n",
    "    priors[name]['net'] = network.NetworkCorner(nbins=priors[name]['A'].nbins, marginals=priors[name]['POI_indices'], \n",
    "                                                param_names=priors[name]['A'].param_names, **hyperparams_point)\n",
    "\n",
    "    priors[name]['net'].load_state_dict(torch.load(priors[name]['net_path']))\n",
    "\n",
    "    with open(priors[name]['results_path']+'/explim_predictions.pickle', 'rb') as file:\n",
    "        priors[name]['predictions'] = {name: pickle.load(file)}\n",
    "\n",
    "    if priors[name]['which_truncation'] > 0:\n",
    "        store_explim = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_explim_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "        store_prior = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_prior_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "    else:\n",
    "        store_explim = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_explim\")\n",
    "        store_prior = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_prior\")\n",
    "    priors[name]['samples_explim'] = store_explim.get_sample_store()\n",
    "    priors[name]['samples_prior'] = store_prior.get_sample_store()\n",
    "    \n",
    "    \n",
    "    del sys.modules['param_function']\n",
    "    del sys.modules['ALP_quick_sim']\n",
    "    del sys.modules['network']\n",
    "    if removed_ALP_sim: sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "264b0409-f3bd-4122-afa8-484ec6b12204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/gertwk/.conda/envs/swyft4-dev-notebook/lib/pyt ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = swyft.SwyftTrainer(accelerator = 'cuda', precision = 64,logger=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b26067dd-14af-4e7f-9b94-0330742811a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_matrices = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b548acfe-ea09-4c84-97d2-bebdfc87a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sys.modules['explim_functions']\n",
    "from explim_functions import find_false_exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d023e335-3246-4472-9984-7ea2635cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fes(prior,name_excl,name_incl,n_limits,n_prior_samples):\n",
    "    \n",
    "    try:\n",
    "        predictions1 = priors[name_excl]['predictions'][prior]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            with open(os.getcwd()+'/predictions-'+name_excl+'-'+prior+'.pickle', 'rb') as file: predictions1 = pickle.load(file)\n",
    "        except FileNotFoundError:\n",
    "            predictions1 = None\n",
    "    try:\n",
    "        predictions2 = priors[name_incl]['predictions'][prior]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            with open(os.getcwd()+'/predictions-'+name_incl+'-'+prior+'.pickle', 'rb') as file: predictions2 = pickle.load(file)\n",
    "        except FileNotFoundError:\n",
    "            predictions2 = None\n",
    "    try:\n",
    "        contour_matrix = contour_matrices[prior+'-'+name_excl+'-'+name_incl]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            with open(os.getcwd()+'/contour_matrix-'+prior+'-'+name_excl+'-'+name_incl+'.pickle', 'rb') as file: contour_matrix = pickle.load(file)\n",
    "        except FileNotFoundError:\n",
    "            contour_matrix = None\n",
    "    \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    fig.add_subplot(1,2,1)\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        \n",
    "        contour_matrix,predictions,_ = find_false_exclusions(\n",
    "            samples = priors[prior]['samples_explim'][:n_limits],\n",
    "            prior_samples1 = priors[name_excl]['samples_prior'][:n_prior_samples],\n",
    "            predictions1=predictions1,\n",
    "            net1 = priors[name_excl]['net'],\n",
    "            trainer = trainer,\n",
    "            \n",
    "            prior_samples2 = priors[name_incl]['samples_prior'][:n_prior_samples],\n",
    "            predictions2=predictions2,\n",
    "            \n",
    "            bounds = [priors[name_excl]['bounds'][0], priors[name_excl]['bounds'][1]],\n",
    "            ax=fig.axes[-1],\n",
    "    \n",
    "            contour_matrix = contour_matrix,\n",
    "            \n",
    "            n_cores = 4,\n",
    "        )\n",
    "        \n",
    "        priors[name_excl]['predictions'][prior] = predictions[0]\n",
    "        priors[name_incl]['predictions'][prior] = predictions[1]\n",
    "        contour_matrices[prior+'-'+name_excl+'-'+name_incl] = contour_matrix\n",
    "    \n",
    "        if name_excl!=prior:\n",
    "            with open(os.getcwd()+'/predictions-'+name_excl+'-'+prior+'.pickle','wb') as file: pickle.dump(predictions[0], file)\n",
    "        if name_incl!=prior:\n",
    "            with open(os.getcwd()+'/predictions-'+name_incl+'-'+prior+'.pickle','wb') as file: pickle.dump(predictions[1], file)\n",
    "        \n",
    "        with open(os.getcwd()+'/contour_matrix-'+prior+'-'+name_excl+'-'+name_incl+'.pickle','wb') as file: pickle.dump(contour_matrix, file)\n",
    "        \n",
    "        fig.savefig(thesis_figs+'false_exclusions.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee7ca68-08c3-44b3-b50d-56b0345f33b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/gertwk/.conda/envs/swyft4-dev-notebook/lib/pyt ...\n",
      "  rank_zero_warn(\n",
      "The following callbacks returned in `LightningModule.configure_callbacks` will override existing callbacks passed to Trainer: EarlyStopping, ModelCheckpoint\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c768c2d0c8f746f99119d87442dd08bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "priors['flare0_semi_informed']['predictions']['flare0_agnostic']=None\n",
    "contour_matrices['flare0_agnostic-flare0_semi_informed-flare0_agnostic'] = None\n",
    "\n",
    "prior = 'flare0_agnostic'\n",
    "name_excl = 'flare0_semi_informed'\n",
    "name_incl = 'flare0_agnostic'\n",
    "\n",
    "n_limits = 400\n",
    "n_prior_samples = 50_000\n",
    "\n",
    "plot_fes(prior,name_excl,name_incl,n_limits,n_prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5562365f-b1ef-4cd9-bdda-40c2823ad17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors['flare0_semi_informed']['predictions']['flare0_agnostic']=None\n",
    "# contour_matrices['flare0_agnostic-flare0_semi_informed-flare0_agnostic'] = None\n",
    "\n",
    "prior = 'flare0_agnostic'\n",
    "name_excl = 'flare0_agnostic'\n",
    "name_incl = 'flare0_semi_informed'\n",
    "\n",
    "n_limits = 400\n",
    "n_prior_samples = 50_000\n",
    "\n",
    "plot_fes(prior,name_excl,name_incl,n_limits,n_prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3f32534-3c8d-484d-9611-f2f879c73ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(contour_matrices['flare0_agnostic-flare0_semi_informed-flare0_agnostic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756dc9b1-9ddf-4fb2-8792-eabe4a4ece81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
