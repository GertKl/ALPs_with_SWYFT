{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7885c4b0-ccb2-49d9-b298-9fd9b7a9c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import swyft\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import importlib\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device_notebook = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import wandb\n",
    "import copy\n",
    "from torch.multiprocessing import Pool\n",
    "torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "torch.set_num_threads(28)\n",
    "import itertools\n",
    "import subprocess\n",
    "from tqdm.auto import tqdm\n",
    "sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n",
    "from explim_functions import generate_expected_limits\n",
    "import sympy as sy\n",
    "from scipy.stats import norm, lognorm\n",
    "from swyft.plot.mass import _get_jefferys_interval as interval\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56feaf19-6395-4d74-a1ff-6d089c02f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"ALPs_with_SWYFT\"\n",
    "thesis_figs = os.getcwd().split(main_dir)[0]+\"/\"+main_dir+\"/thesis_figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875729e6-31ab-4306-bc54-618e6d81cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "names = ['flare0_informed',]\n",
    "colors_priors = ['r','#FFA500','y','g','b', ]\n",
    "\n",
    "priors = {}\n",
    "for ip, name in enumerate(names):\n",
    "\n",
    "    priors[name] = {'name': name}\n",
    "\n",
    "    priors[name]['results_path'] = '/home/gertwk/ALPs_with_SWYFT/cluster_runs/analysis_results/'+name\n",
    "\n",
    "    priors[name]['store_path'] = priors[name]['results_path']+\"/sim_output/store\"\n",
    "\n",
    "    priors[name]['config_vars'] = priors[name]['results_path'] +'/config_variables.pickle'\n",
    "\n",
    "    priors[name]['config_phys'] = priors[name]['results_path'] +'/physics_variables.pickle'\n",
    "    \n",
    "    priors[name]['truncation_record'] = priors[name]['results_path'] +'/truncation_record.pickle'\n",
    "\n",
    "    removed_ALP_sim=0\n",
    "    try:\n",
    "        sys.path.remove('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n",
    "        removed_ALP_sim=1\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        del sys.modules['ALP_quick_sim']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    sys.path.append(priors[name]['results_path'])\n",
    "    import param_function\n",
    "    import ALP_quick_sim\n",
    "    with open(priors[name]['config_vars'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    with open(priors[name]['config_phys'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    with open(priors[name]['truncation_record'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    sys.path.remove(priors[name]['results_path'])\n",
    "    sys.path.append(priors[name]['results_path']+'/train_output/net')\n",
    "    import network\n",
    "    sys.path.remove(priors[name]['results_path']+'/train_output/net')\n",
    "    \n",
    "    count = 0\n",
    "    for combo in itertools.product(*priors[name]['hyperparams'].values()):\n",
    "        if count == priors[name]['which_grid_point']:\n",
    "            hyperparams_point = {}\n",
    "            for i, key in enumerate(priors[name]['hyperparams'].keys()):\n",
    "                hyperparams_point[key]=combo[i]\n",
    "        count +=1\n",
    "\n",
    "    priors[name]['net_path'] = {}\n",
    "    priors[name]['net'] = {}\n",
    "    for rnd in range(priors[name]['which_truncation']+1):\n",
    "        round = 'round_'+str(rnd)\n",
    "        priors[name]['net_path'][round] = (priors[name]['results_path'] + '/train_output/net/trained_network_'\n",
    "                                                         +round+'_gridpoint_'+str(priors[name]['which_grid_point'])+'.pt')\n",
    "        priors[name]['net'][round] = network.NetworkCorner(\n",
    "            nbins=priors[name]['A'].nbins,\n",
    "            marginals=priors[name]['POI_indices'],\n",
    "            param_names=priors[name]['A'].param_names,\n",
    "            **hyperparams_point,\n",
    "        )\n",
    "        priors[name]['net'][round].load_state_dict(torch.load(priors[name]['net_path'][round]))\n",
    "\n",
    "    with open(priors[name]['results_path']+'/explim_predictions.pickle', 'rb') as file:\n",
    "        priors[name]['predictions'] = pickle.load(file)\n",
    "\n",
    "    if priors[name]['which_truncation'] > 0:\n",
    "        store = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "        store_explim = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_explim_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "        store_prior = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_prior_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "    else:\n",
    "        store = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name'])\n",
    "        store_explim = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_explim\")\n",
    "        store_prior = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_prior\")\n",
    "    priors[name]['samples'] = store.get_sample_store()\n",
    "    priors[name]['samples_explim'] = store_explim.get_sample_store()\n",
    "    priors[name]['samples_prior'] = store_prior.get_sample_store()\n",
    " \n",
    "    del sys.modules['param_function']\n",
    "    del sys.modules['ALP_quick_sim']\n",
    "    del sys.modules['network']\n",
    "    if removed_ALP_sim: sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339b4fe7-b2bd-4a4c-be5c-01cafebeb8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/gertwk/.conda/envs/swyft4-dev-notebook/lib/pyt ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = swyft.SwyftTrainer(accelerator = 'cuda', precision = 64,logger=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb27e054-6bab-4c12-8d90-1374bf989d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7af9786-3a1b-4247-a172-23c26ce443ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pair_to_index(pair,n_indices):\n",
    "    pair = sorted(pair)\n",
    "    return int((pair[0]+1)*(n_indices-1+n_indices-pair[0]-1)/2 - n_indices + pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6d358e-2538-4bdf-883a-2da94cb5165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(exp,n_bins):\n",
    "    x = np.linspace(-1,1,n_bins)\n",
    "    return 0.5+0.5*np.cos(np.pi*np.sign(x)*np.abs(x)**exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110e313d-fa3c-4992-ba22-386886c2e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdnorm = norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024b750-691b-4a32-821b-07f633bf6123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e74571-219a-4416-a305-c876e5effe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_to_z(x):\n",
    "    return stdnorm.ppf(0.5+x/2)\n",
    "\n",
    "def z_to_p(x):\n",
    "    return stdnorm.cdf(x)-stdnorm.cdf(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4430502f-9e21-4f1c-a073-e11163d93372",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del sys.modules['DRP_test']\n",
    "except KeyError:\n",
    "    pass\n",
    "try:\n",
    "    del sys.modules['reference_functions']\n",
    "except KeyError:\n",
    "    pass\n",
    "from DRP_test import get_drp_coverage, get_drp_coverage_torch, draw_DRP_samples_fast\n",
    "from reference_functions import References\n",
    "R = References()\n",
    "references2D = R.references2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2830c78-a9e7-44cd-9414-c5686c86dfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samps = 10_000\n",
    "n_prior_samps=10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add849cb-39c7-4e13-8e9a-c9f13792158f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3afebf5a884f13a0de9d7cafe184ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa830557c8c4d8ab36805a366781c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f04d4118b8449db36738bcfe934708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b48f3234af4527930e52fe4f194a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = names[0]\n",
    "samples = priors[name]['samples'][-10_000:]\n",
    "prior_samples = priors[name]['samples_prior'][:10_000]\n",
    "which_truncation = priors[name]['which_truncation']\n",
    "which_grid_point = priors[name]['which_grid_point']\n",
    "POIs = priors[name]['POI_indices']\n",
    "A = priors[name]['A']\n",
    "bounds = np.array(priors[name]['bounds_rounds'][which_grid_point][which_truncation])\n",
    "\n",
    "draws1d = {}\n",
    "draws2d = {}\n",
    "weights1d = {}\n",
    "weights2d = {}\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    draws1d[round],draws2d[round],weights1d[round],weights2d[round] = draw_DRP_samples_fast(\n",
    "        priors[name]['net'][round],\n",
    "        trainer,\n",
    "        samples,\n",
    "        prior_samples,\n",
    "        batch_size = 1024*4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbc200e5-a768-457a-9983-26e706f7192c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# name = names[0]\n",
    "# samples = priors[name]['samples'][-5_000:]\n",
    "# prior_samples = priors[name]['samples_prior'][:50_000]\n",
    "# which_truncation = priors[name]['which_truncation']\n",
    "# which_grid_point = priors[name]['which_grid_point']\n",
    "# POIs = priors[name]['POI_indices']\n",
    "# A = priors[name]['A']\n",
    "# bounds = np.array(priors[name]['bounds_rounds'][which_grid_point][which_truncation])\n",
    "\n",
    "# # draws1d = {}\n",
    "# # draws2d = {}\n",
    "# # weights1d = {}\n",
    "# # weights2d = {}\n",
    "# for rnd in range(0,2):\n",
    "#     round = 'round_'+str(rnd)\n",
    "#     draws1d[round],draws2d[round],weights1d[round],weights2d[round] = draw_DRP_samples_fast(\n",
    "#         priors[name]['net'][round],\n",
    "#         trainer,\n",
    "#         samples,\n",
    "#         prior_samples,\n",
    "#         batch_size = 1024*4\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa78750-fdc8-4bff-b267-cbf1b624aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This estimates the mass of highest-likelihood intervals.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816d5db8b5d64bdc944ec96212ed5057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1dee03dc5fa4a42bce3d5bcfdd6e521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This estimates the mass of highest-likelihood intervals.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a4bf3135c34246b77e248912d8cb99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72f06df7a2b4de3bd8987c0fe3c672b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "coverage_samples = {}\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    coverage_samples[round] = trainer.test_coverage(priors[name]['net'][round], samples, prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffee245-bc1d-4bf8-813a-e14cefc08c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_colors = ['r','y','g','b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794b030-8949-4274-892a-14f3bd752647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(color1, color2, amount=0.5):\n",
    "    return tuple(np.array(color1)*amount + np.array(color2)*(1-amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc7050-b82c-4110-8ff7-3c6f7b032d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "which_truncation = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcc01d-f07c-433e-8e1f-2a3c66ecfe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_refs = 100\n",
    "references_1d = [\n",
    "    references2D(samples)[0][:,[0]] for _ in range(n_refs)\n",
    "]\n",
    "\n",
    "references_2d = [\n",
    "    references2D(samples)[0] for _ in range(n_refs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e7ab2-0ce8-4bb7-8e40-2c5eb55cfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ecp_pp = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "alpha_pp = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "ecp_zz = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "alpha_zz = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "f_pp = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "f_zz = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "\n",
    "validation_sums = { 'round_'+str(rnd) : [{},{}] for rnd in range(which_truncation+1) }\n",
    "\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    for ref_i in range(len(references_1d)):\n",
    "\n",
    "        random_indices = random.sample(list(np.arange(len(samples))), n_samps)\n",
    "        random_prior_indices = random.sample(list(np.arange(len(prior_samples))), n_prior_samps)\n",
    "\n",
    "        for i, key in enumerate(draws1d[round].keys()):\n",
    "    \n",
    "            ecp_pp[round][0][ref_i][key], alpha_pp[round][0][ref_i][key], ecp_zz[round][0][ref_i][key], alpha_zz[round][0][ref_i][key], f_pp[round][0][ref_i][key], f_zz[round][0][ref_i][key], f_score, _ = get_drp_coverage_torch(\n",
    "                draws1d[round][key][random_prior_indices][:,random_indices,:],\n",
    "                samples['params'][:,[POIs[i]]][random_indices],\n",
    "                weights = weights1d[round][key][random_prior_indices][:,random_indices],\n",
    "                theta_names=A.param_names[POIs[i]],\n",
    "                bounds = np.array(bounds)[[POIs[i]]],\n",
    "                references = references_1d[ref_i][random_indices],\n",
    "                device='cuda',\n",
    "                intermediate_figures=False,\n",
    "            )\n",
    "\n",
    "            if ref_i == 0: validation_sums[round][0][key] = 0\n",
    "            # uncertainty = (interval((alpha_pp[round][0][ref_i][key]*n_samps).astype(int),n_samps)[:,1]-interval((alpha_pp[round][0][ref_i][key]*n_samps).astype(int),n_samps)[:,0])/2\n",
    "            # validation_sums[round][0][key] += np.sum(((ecp_pp[round][0][ref_i][key]-alpha_pp[round][0][ref_i][key])/uncertainty)**2)/n_samps\n",
    "            validation_sums[round][0][key] += f_score/n_refs\n",
    "            \n",
    "rows = len(POIs)\n",
    "\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    for ref_i in range(len(references_2d)): \n",
    "        row = 0\n",
    "        column = 0\n",
    "\n",
    "        random_indices = random.sample(list(np.arange(len(samples))), n_samps)\n",
    "        random_prior_indices = random.sample(list(np.arange(len(prior_samples))), n_prior_samps)\n",
    "        \n",
    "        for i, key in enumerate(draws2d[round].keys()):\n",
    "            row+=1\n",
    "            if row >= rows:\n",
    "                column+=1\n",
    "                row = 1+column    \n",
    "            ecp_pp[round][1][ref_i][key], alpha_pp[round][1][ref_i][key], ecp_zz[round][1][ref_i][key], alpha_zz[round][1][ref_i][key], f_pp[round][1][ref_i][key],f_zz[round][0][ref_i][key], f_score, _ = get_drp_coverage_torch(\n",
    "                draws2d[round][key][random_prior_indices][:,random_indices,:],\n",
    "                samples['params'][:,[column,row]][random_indices],\n",
    "                weights = weights2d[round][key][random_prior_indices][:,random_indices],\n",
    "                theta_names=np.array(A.param_names)[[column,row]],\n",
    "                bounds = np.array(bounds)[[column,row]],\n",
    "                references = references_2d[ref_i][random_indices],\n",
    "                device='cuda',\n",
    "                intermediate_figures=False,\n",
    "            )\n",
    "\n",
    "            if ref_i == 0: validation_sums[round][1][key] = 0\n",
    "            # uncertainty = (interval((alpha_pp[round][1][ref_i][key]*n_samps).astype(int),n_samps)[:,1]-interval((alpha_pp[round][1][ref_i][key]*n_samps).astype(int),n_samps)[:,0])/2\n",
    "            # validation_sums[round][1][key] += np.sum(((ecp_pp[round][1][ref_i][key]-alpha_pp[round][1][ref_i][key])/uncertainty)**2)/n_refs\n",
    "            validation_sums[round][1][key] += f_score/n_refs\n",
    "\n",
    "for i, key in enumerate(draws1d['round_0'].keys()):\n",
    "    print(key)\n",
    "    for rnd in range(which_truncation+1):\n",
    "        print(validation_sums['round_'+str(rnd)][0][key])\n",
    "    print()\n",
    "\n",
    "for i, key in enumerate(draws2d['round_0'].keys()):\n",
    "    print(key)\n",
    "    for rnd in range(which_truncation+1):\n",
    "        print(validation_sums['round_'+str(rnd)][1][key])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b3b37-3199-4446-98d3-169e19f9ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "label_size = 15\n",
    "label_pad = 0\n",
    "tick_size = 10\n",
    "x_tick_pad = 1\n",
    "y_tick_pad = -1\n",
    "x_tick_rotation = 45\n",
    "y_tick_rotation = 45\n",
    "max_z =3\n",
    "significance1 = 5/n_samps\n",
    "significance2 = 1/n_samps\n",
    "blend_amount = 0.5\n",
    "opacity = 0.25\n",
    "\n",
    "x_axis_pp = \"$1-\\\\alpha$\"\n",
    "y_axis_pp = \"$\\mathrm{ECP}$\"\n",
    "ticks_pp = [0.5,0.68,0.95]\n",
    "\n",
    "x_axis_zz = \"$Z_{1-\\\\alpha}$\"\n",
    "y_axis_zz = \"$Z_\\mathrm{ECP}$\"\n",
    "ticks_zz = [1,2,3]\n",
    "\n",
    "x_axis_rel = \"$1-\\\\alpha$\"\n",
    "y_axis_rel = \"$\\mathrm{ECP}$ residuals\"\n",
    "ticks_rel = ticks_pp\n",
    "\n",
    "x_axis_rel_zz = \"$Z_{1-\\\\alpha}$\"\n",
    "y_axis_rel_zz = \"$Z_\\mathrm{ECP}$ residuals\"\n",
    "ticks_rel_zz = ticks_zz\n",
    "\n",
    "POI_names = ['$m_a$', '$g_{a \\\\gamma}$', 'Spectral Amplitude', 'Spectral Index', 'Cut-off Energy']\n",
    "\n",
    "x_axis_list = [x_axis_pp,x_axis_zz,x_axis_rel,x_axis_rel_zz,x_axis_pp,x_axis_zz]\n",
    "y_axis_list = [y_axis_pp,y_axis_zz,y_axis_rel,y_axis_rel_zz,y_axis_pp,y_axis_zz]\n",
    "tick_list = [ticks_pp,ticks_zz,ticks_pp,ticks_zz,ticks_pp,ticks_zz]\n",
    "\n",
    "adjusted_colors = [blend(to_rgb(col),(1,1,1),amount=blend_amount) for col in round_colors[:-1]]\n",
    "\n",
    "rows = len(POIs)\n",
    "\n",
    "DRP_fig_pp = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_zz = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_rel = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_rel_zz = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_HPD_pp = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_HPD_zz = plt.figure(figsize = (12, 12))\n",
    "\n",
    "fig_list = [DRP_fig_pp,DRP_fig_zz,DRP_fig_rel,DRP_fig_rel_zz, DRP_fig_HPD_pp,DRP_fig_HPD_zz]\n",
    "\n",
    "row = -1\n",
    "column = 0\n",
    "index_1d=-1\n",
    "index_2d=-1\n",
    "keys_1d = list(draws1d['round_0'].keys())\n",
    "keys_2d = list(draws2d['round_0'].keys())\n",
    "make_extra_plot = False\n",
    "gs = gridspec.GridSpec(5,5)\n",
    "i = -1\n",
    "while i < len(keys_1d)+len(keys_2d)-1:\n",
    "    i+=1\n",
    "    print(str(i)+'/'+str(len(keys_1d)+len(keys_2d)),flush=True,end='\\r')\n",
    "    if not make_extra_plot:\n",
    "        row+=1\n",
    "        if row == rows:\n",
    "            column+=1\n",
    "            row = column\n",
    "        if row == column:\n",
    "            dims = 0\n",
    "            index_1d += 1\n",
    "            key = keys_1d[index_1d]\n",
    "        else:\n",
    "            dims = 1\n",
    "            index_2d += 1\n",
    "            key = keys_2d[index_2d]\n",
    "\n",
    "        for fig_i, fig in enumerate(fig_list): fig.add_subplot(rows, rows, rows*row+column+1)\n",
    "            \n",
    "    else:\n",
    "        for fig_i, fig in enumerate(fig_list): fig.add_subplot(gs[:-3,3:])\n",
    "\n",
    "    for fig_i, fig in enumerate(fig_list): \n",
    "        fig.axes[-1].tick_params(axis='y',labelsize=tick_size,rotation=y_tick_rotation, pad=y_tick_pad)\n",
    "        fig.axes[-1].set_xticks(tick_list[fig_i])\n",
    "        fig.axes[-1].set_xticklabels([])\n",
    "    DRP_fig_pp.axes[-1].set_yticks(ticks_pp)\n",
    "    DRP_fig_zz.axes[-1].set_yticks(ticks_zz)\n",
    "    DRP_fig_HPD_pp.axes[-1].set_yticks(ticks_pp)\n",
    "    DRP_fig_HPD_zz.axes[-1].set_yticks(ticks_zz)\n",
    "    DRP_fig_pp.axes[-1].set_yticklabels([])\n",
    "    DRP_fig_zz.axes[-1].set_yticklabels([])\n",
    "    DRP_fig_HPD_pp.axes[-1].set_yticklabels([])\n",
    "    DRP_fig_HPD_zz.axes[-1].set_yticklabels([])\n",
    "\n",
    "    if row==column:\n",
    "        for fig_i, fig in enumerate(fig_list): fig.axes[-1].set_title(POI_names[row])\n",
    "  \n",
    "    if row==rows-1:\n",
    "        for fig_i, fig in enumerate(fig_list): \n",
    "            fig.axes[-1].tick_params(axis='x',labelsize=tick_size,pad=x_tick_pad,rotation=x_tick_rotation)\n",
    "            fig.axes[-1].set_xticks(tick_list[fig_i])\n",
    "            fig.axes[-1].set_xlabel(x_axis_list[fig_i], fontsize=label_size, labelpad=label_pad)\n",
    "        \n",
    "    if column == 0:\n",
    "        for fig_i, fig in enumerate(fig_list): \n",
    "            fig.axes[-1].set_ylabel(y_axis_list[fig_i], fontsize=label_size, labelpad=label_pad)\n",
    "        DRP_fig_pp.axes[-1].set_yticklabels(ticks_pp)\n",
    "        DRP_fig_zz.axes[-1].set_yticklabels(ticks_zz)\n",
    "        DRP_fig_HPD_pp.axes[-1].set_yticklabels(ticks_pp)\n",
    "        DRP_fig_HPD_zz.axes[-1].set_yticklabels(ticks_zz)\n",
    " \n",
    "    for rnd in range(which_truncation+1):\n",
    "        round = 'round_'+str(rnd)\n",
    "        for ref_i in range(len(references_2d)):\n",
    "            ecp_ex_pp = np.zeros(len(ecp_pp[round][dims][ref_i][key])+1)\n",
    "            alpha_ex_pp = np.zeros(len(alpha_pp[round][dims][ref_i][key])+1)\n",
    "            ecp_ex_zz = np.zeros(len(ecp_zz[round][dims][ref_i][key])+1)\n",
    "            alpha_ex_zz_orig = np.zeros(len(alpha_zz[round][dims][ref_i][key])+1)\n",
    "            ecp_ex_pp[1:] = ecp_pp[round][dims][ref_i][key]\n",
    "            alpha_ex_pp[1:] = alpha_pp[round][dims][ref_i][key]\n",
    "            ecp_ex_zz[1:] = ecp_zz[round][dims][ref_i][key]\n",
    "            alpha_ex_zz_orig[1:] = alpha_zz[round][dims][ref_i][key]\n",
    "            alpha_ex_zz = alpha_ex_zz_orig[alpha_ex_zz_orig<=max_z]\n",
    "            ecp_ex_zz = ecp_ex_zz[alpha_ex_zz_orig<=max_z]\n",
    "            if rnd < which_truncation:\n",
    "                label = 'Range before truncation #' + str(rnd+1) if ref_i == 0 else None\n",
    "                DRP_fig_pp.axes[-1].fill_between(alpha_ex_pp,ecp_ex_pp,alpha_ex_pp, color=adjusted_colors[rnd],label=label)\n",
    "                DRP_fig_zz.axes[-1].fill_between(alpha_ex_zz,ecp_ex_zz,alpha_ex_zz, color=adjusted_colors[rnd],label=label)\n",
    "                DRP_fig_rel.axes[-1].fill_between(alpha_ex_pp,(ecp_ex_pp-alpha_ex_pp),np.zeros(len(alpha_ex_pp)), color=adjusted_colors[rnd],label=label)\n",
    "                DRP_fig_rel_zz.axes[-1].fill_between(alpha_ex_zz,(ecp_ex_zz-alpha_ex_zz),np.zeros(len(alpha_ex_zz)), color=adjusted_colors[rnd],label=label)  \n",
    "            else:\n",
    "                label = 'Final coverages' if ref_i == 0 else None\n",
    "                DRP_fig_pp.axes[-1].plot(alpha_ex_pp, ecp_ex_pp, round_colors[rnd],alpha=opacity,label=label)\n",
    "                DRP_fig_zz.axes[-1].plot(alpha_ex_zz, ecp_ex_zz, round_colors[rnd],alpha=opacity,label=label)\n",
    "                DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (ecp_ex_pp-alpha_ex_pp), round_colors[rnd],alpha=opacity,label=label)\n",
    "                DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (ecp_ex_zz-alpha_ex_zz), round_colors[rnd],alpha=opacity,label=label)\n",
    "            if dims == 0:\n",
    "                swyft.plot_pp(coverage_samples[round], key,ax = DRP_fig_HPD_pp.axes[-1])\n",
    "                swyft.plot_zz(coverage_samples[round], key,ax = DRP_fig_HPD_zz.axes[-1])\n",
    "            else:\n",
    "                swyft.plot_pp(coverage_samples[round], eval(key.replace(' ',',')),ax = DRP_fig_HPD_pp.axes[-1])\n",
    "                swyft.plot_zz(coverage_samples[round], eval(key.replace(' ',',')),ax = DRP_fig_HPD_zz.axes[-1])\n",
    "\n",
    "\n",
    "    uncertainty1 = interval((alpha_ex_pp*n_samps).astype(int),n_samps,alpha = significance1)\n",
    "    upper_uncertainty1 = uncertainty1[:,0]\n",
    "    lower_uncertainty1 = uncertainty1[:,1]\n",
    "    uncertainty2 = interval((alpha_ex_pp*n_samps).astype(int),n_samps,alpha = significance2)\n",
    "    upper_uncertainty2 = uncertainty2[:,0]\n",
    "    lower_uncertainty2 = uncertainty2[:,1]\n",
    "    uncertainty1_zz = interval((z_to_p(alpha_ex_zz)*n_samps).astype(int),n_samps,alpha=significance1)\n",
    "    upper_uncertainty1_zz = p_to_z(uncertainty1_zz[:,1])\n",
    "    lower_uncertainty1_zz = p_to_z(uncertainty1_zz[:,0])\n",
    "    uncertainty2_zz = interval((z_to_p(alpha_ex_zz)*n_samps).astype(int),n_samps,alpha=significance2)\n",
    "    upper_uncertainty2_zz = p_to_z(uncertainty2_zz[:,1])\n",
    "    lower_uncertainty2_zz = p_to_z(uncertainty2_zz[:,0])\n",
    "\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, upper_uncertainty1,'k--', label='Significance = {:1g}'.format(significance1))\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, lower_uncertainty1,'k--')\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, upper_uncertainty2,'k:', label='Significance = {:1g}'.format(significance2))\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, lower_uncertainty2,'k:')\n",
    "    \n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (upper_uncertainty1-alpha_ex_pp), 'k--',label='Significance '+str(significance1))\n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (lower_uncertainty1-alpha_ex_pp), 'k--')\n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (upper_uncertainty2-alpha_ex_pp), 'k:',label='Significance '+str(significance2))\n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (lower_uncertainty2-alpha_ex_pp), 'k:')\n",
    "\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, upper_uncertainty1_zz,'k--',label='Significance = {:1g}'.format(significance1))\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, lower_uncertainty1_zz,'k--')\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, upper_uncertainty2_zz,'k:',label='Significance = {:1g}'.format(significance2))\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, lower_uncertainty2_zz,'k:')\n",
    "    \n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (upper_uncertainty1_zz-alpha_ex_zz), 'k--',label='Significance = {:1g}'.format(significance1))\n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (lower_uncertainty1_zz-alpha_ex_zz), 'k--')\n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (upper_uncertainty2_zz-alpha_ex_zz), 'k:',label='Significance = {:1g}'.format(significance2))\n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (lower_uncertainty2_zz-alpha_ex_zz), 'k:')\n",
    "\n",
    "\n",
    "    if row==1 and column==0:\n",
    "        if not make_extra_plot:\n",
    "            i -= 1\n",
    "            make_extra_plot=True\n",
    "        else:\n",
    "            make_extra_plot=False\n",
    "\n",
    "            extra_title = 'Combined coverage for ('+POI_names[0]+','+POI_names[1]+')'\n",
    "            extra_title_size = 15\n",
    "            extra_legend_size = 10\n",
    "            extra_legend_loc = (-0.92,0.62)\n",
    "\n",
    "            for fig_i, fig in enumerate(fig_list):\n",
    "                fig.axes[-1].set_xticks(tick_list[fig_i])\n",
    "                fig.axes[-1].set_xticklabels(tick_list[fig_i])\n",
    "                fig.axes[-1].tick_params(axis='x',labelsize=tick_size,pad=x_tick_pad)\n",
    "                fig.axes[-1].tick_params(axis='y',labelsize=tick_size,pad=y_tick_pad)\n",
    "                fig.axes[-1].set_xlabel(x_axis_list[fig_i], fontsize=label_size, labelpad=label_pad)\n",
    "                fig.axes[-1].set_ylabel(y_axis_list[fig_i], fontsize=label_size, labelpad=label_pad)\n",
    "                fig.axes[-1].set_title(extra_title, fontsize=extra_title_size)\n",
    "                fig.axes[-1].legend(prop={'size': extra_legend_size}, loc = extra_legend_loc)\n",
    "           \n",
    "            # DRP_fig_pp.axes[-1].set_yticks(ticks_pp)\n",
    "            DRP_fig_pp.axes[-1].set_yticklabels(ticks_pp)\n",
    "            # DRP_fig_zz.axes[-1].set_yticks(ticks_zz)\n",
    "            DRP_fig_zz.axes[-1].set_yticklabels(ticks_zz)\n",
    "            DRP_fig_HPD_pp.axes[-1].set_yticklabels(ticks_pp)\n",
    "            DRP_fig_HPD_zz.axes[-1].set_yticklabels(ticks_zz)\n",
    "  \n",
    "\n",
    "DRP_fig_pp.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "DRP_fig_zz.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "DRP_fig_rel.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "DRP_fig_rel_zz.subplots_adjust(hspace=0.15, wspace=0.15)\n",
    "DRP_fig_HPD_pp.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "DRP_fig_HPD_zz.subplots_adjust(hspace=0.1, wspace=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f4742-9bfd-4b26-86ed-ea797f3ee575",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_pp.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_pp.axes[5].set_visible(True)\n",
    "DRP_fig_pp.axes[5].plot(alpha_ex_pp,interval((alpha_ex_pp*n_samps).astype(int),n_samps)[:,0], 'k:')\n",
    "DRP_fig_pp.axes[5].plot(alpha_ex_pp,interval((alpha_ex_pp*n_samps).astype(int),n_samps)[:,1], 'k:')\n",
    "DRP_fig_pp.set_figheight(12*5)\n",
    "DRP_fig_pp.set_figwidth(12*5)\n",
    "DRP_fig_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f2b1b-9310-414e-a5bf-84c0aa845d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_zz.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_zz.axes[5].set_visible(True)\n",
    "DRP_fig_zz.axes[5].plot(alpha_ex_zz,p_to_z(interval((z_to_p(alpha_ex_zz)*n_samps).astype(int),n_samps)[:,0]), 'k:')\n",
    "DRP_fig_zz.axes[5].plot(alpha_ex_zz,p_to_z(interval((z_to_p(alpha_ex_zz)*n_samps).astype(int),n_samps)[:,1]), 'k:')\n",
    "DRP_fig_zz.set_figheight(12*5)\n",
    "DRP_fig_zz.set_figwidth(12*5)\n",
    "DRP_fig_zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e559c7-cb61-4dbd-948c-ea76800d293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_zz.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_zz.axes[5].set_visible(True)\n",
    "DRP_fig_zz.axes[5].plot(alpha_ex_zz,p_to_z(interval((z_to_p(alpha_ex_zz)*n_samps).astype(int),n_samps)[:,0]), 'k:')\n",
    "DRP_fig_zz.axes[5].plot(alpha_ex_zz,p_to_z(interval((z_to_p(alpha_ex_zz)*n_samps).astype(int),n_samps)[:,1]), 'k:')\n",
    "DRP_fig_zz.axes[5].set_ylim(0,3.5)\n",
    "DRP_fig_zz.set_figheight(12*5)\n",
    "DRP_fig_zz.set_figwidth(12*5)\n",
    "DRP_fig_zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f86c2-7695-44c7-89c7-9f12295993e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_rel.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_rel.axes[5].set_visible(True)\n",
    "DRP_fig_rel.set_figheight(12*5)\n",
    "DRP_fig_rel.set_figwidth(12*5)\n",
    "DRP_fig_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60224cb-5598-4144-9bf9-8fb421f8d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_rel_zz.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_rel_zz.axes[5].set_visible(True)\n",
    "DRP_fig_rel_zz.axes[5].set_xlim([0,2.8])\n",
    "DRP_fig_rel_zz.axes[5].set_ylim([-2.5,3])\n",
    "DRP_fig_rel_zz.set_figheight(12*5)\n",
    "DRP_fig_rel_zz.set_figwidth(12*5)\n",
    "DRP_fig_rel_zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89de4e11-4ea2-4284-96b1-2fcb0b531f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
