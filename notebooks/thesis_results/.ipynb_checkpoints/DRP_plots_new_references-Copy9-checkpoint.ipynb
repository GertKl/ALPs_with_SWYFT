{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7885c4b0-ccb2-49d9-b298-9fd9b7a9c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import swyft\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import importlib\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device_notebook = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import wandb\n",
    "import copy\n",
    "from torch.multiprocessing import Pool\n",
    "torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "torch.set_num_threads(28)\n",
    "import itertools\n",
    "import subprocess\n",
    "from tqdm.auto import tqdm\n",
    "sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n",
    "from explim_functions import generate_expected_limits\n",
    "import sympy as sy\n",
    "from scipy.stats import norm, lognorm\n",
    "from swyft.plot.mass import _get_jefferys_interval as interval\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56feaf19-6395-4d74-a1ff-6d089c02f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"ALPs_with_SWYFT\"\n",
    "thesis_figs = os.getcwd().split(main_dir)[0]+\"/\"+main_dir+\"/thesis_figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875729e6-31ab-4306-bc54-618e6d81cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "names = ['grid_informed_power5',]\n",
    "gridpoints = [50,55]\n",
    "colors_priors = ['r','#FFA500','y','g','b', ]\n",
    "\n",
    "priors = {}\n",
    "for ip, name in enumerate(names):\n",
    "\n",
    "    priors[name] = {'name': name}\n",
    "\n",
    "    priors[name]['results_path'] = '/home/gertwk/ALPs_with_SWYFT/cluster_runs/analysis_results/'+name\n",
    "\n",
    "    priors[name]['store_path'] = priors[name]['results_path']+\"/sim_output/store\"\n",
    "\n",
    "    priors[name]['config_vars'] = priors[name]['results_path'] +'/config_variables.pickle'\n",
    "\n",
    "    priors[name]['config_phys'] = priors[name]['results_path'] +'/physics_variables.pickle'\n",
    "    \n",
    "    priors[name]['truncation_record'] = priors[name]['results_path'] +'/truncation_record.pickle'\n",
    "\n",
    "    removed_ALP_sim=0\n",
    "    try:\n",
    "        sys.path.remove('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n",
    "        removed_ALP_sim=1\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        del sys.modules['ALP_quick_sim']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    sys.path.append(priors[name]['results_path'])\n",
    "    import param_function\n",
    "    import ALP_quick_sim\n",
    "    with open(priors[name]['config_vars'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    with open(priors[name]['config_phys'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    with open(priors[name]['truncation_record'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    sys.path.remove(priors[name]['results_path'])\n",
    "    sys.path.append(priors[name]['results_path']+'/train_output/net')\n",
    "    import network\n",
    "    sys.path.remove(priors[name]['results_path']+'/train_output/net')\n",
    "    \n",
    "    \n",
    "\n",
    "    priors[name]['net_path'] = {}\n",
    "    priors[name]['net'] = {}\n",
    "    for rnd in range(priors[name]['which_truncation']+1):\n",
    "        round = 'round_'+str(rnd)\n",
    "        priors[name]['net'][round] = {}\n",
    "        priors[name]['net_path'][round] = {}\n",
    "        for gp in gridpoints:\n",
    "            gridpoint = 'grid_point_' + str(gp)\n",
    "            priors[name]['net_path'][round][gridpoint] = (priors[name]['results_path'] + '/train_output/net/trained_network_'\n",
    "                                                             +round+'_gridpoint_'+str(int(gp))+'.pt')\n",
    "\n",
    "            count = 0\n",
    "            for combo in itertools.product(*priors[name]['hyperparams'].values()):\n",
    "                if count == gp:\n",
    "                    hyperparams_point = {}\n",
    "                    for i, key in enumerate(priors[name]['hyperparams'].keys()):\n",
    "                        hyperparams_point[key]=combo[i]\n",
    "                    break\n",
    "                count +=1\n",
    "          \n",
    "            priors[name]['net'][round][gridpoint] = network.NetworkCorner(\n",
    "                nbins=priors[name]['A'].nbins,\n",
    "                marginals=priors[name]['POI_indices'],\n",
    "                param_names=priors[name]['A'].param_names,\n",
    "                **hyperparams_point,\n",
    "            )\n",
    "            priors[name]['net'][round][gridpoint].load_state_dict(torch.load(priors[name]['net_path'][round][gridpoint]))\n",
    "\n",
    "    # with open(priors[name]['results_path']+'/explim_predictions.pickle', 'rb') as file:\n",
    "    #     priors[name]['predictions'] = pickle.load(file)\n",
    "\n",
    "    if priors[name]['which_truncation'] > 0:\n",
    "        store = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "        # store_explim = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_explim_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "        store_prior = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_prior_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "    else:\n",
    "        store = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name'])\n",
    "        # store_explim = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_explim\")\n",
    "        store_prior = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_prior\")\n",
    "    priors[name]['samples'] = store.get_sample_store()\n",
    "    # priors[name]['samples_explim'] = store_explim.get_sample_store()\n",
    "    priors[name]['samples_prior'] = store_prior.get_sample_store()\n",
    " \n",
    "    del sys.modules['param_function']\n",
    "    del sys.modules['ALP_quick_sim']\n",
    "    del sys.modules['network']\n",
    "    if removed_ALP_sim: sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339b4fe7-b2bd-4a4c-be5c-01cafebeb8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/gertwk/.conda/envs/swyft4-dev-notebook/lib/pyt ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = swyft.SwyftTrainer(accelerator = 'cuda', precision = 32,logger=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72f18655-c822-47a8-b8a7-c667f7d668bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/gertwk/ALPs_with_SWYFT/notebooks/thesis_results',\n",
       " '/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python39.zip',\n",
       " '/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9',\n",
       " '/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/lib-dynload',\n",
       " '',\n",
       " '/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages',\n",
       " '/tmp/tmplqh3r4do',\n",
       " '/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7af9786-3a1b-4247-a172-23c26ce443ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pair_to_index(pair,n_indices):\n",
    "    pair = sorted(pair)\n",
    "    return int((pair[0]+1)*(n_indices-1+n_indices-pair[0]-1)/2 - n_indices + pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6d358e-2538-4bdf-883a-2da94cb5165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(exp,n_bins):\n",
    "    x = np.linspace(-1,1,n_bins)\n",
    "    return 0.5+0.5*np.cos(np.pi*np.sign(x)*np.abs(x)**exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110e313d-fa3c-4992-ba22-386886c2e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdnorm = norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a44f1d2-61cc-4089-85c9-649a100b7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# references_2d = [\n",
    "#                 references2D(priors[name]['samples'][-1000:])[0] for _ in range(1000)\n",
    "#             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbdac0b6-c33a-4c7d-91bf-5635dc34946a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(priors[name]['samples_prior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4430502f-9e21-4f1c-a073-e11163d93372",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del sys.modules['DRP_test']\n",
    "except KeyError:\n",
    "    pass\n",
    "try:\n",
    "    del sys.modules['reference_functions']\n",
    "except KeyError:\n",
    "    pass\n",
    "from DRP_test import get_drp_coverage, get_drp_coverage_torch, draw_DRP_samples_fast\n",
    "from reference_functions import References\n",
    "R = References()\n",
    "references2D = R.references2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fe500b0-7762-4d4f-8a85-650d81da4298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa752816c51847b7a232a29f09da30f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = names[0]\n",
    "samples = priors[name]['samples'][-4_000:]\n",
    "prior_samples = priors[name]['samples_prior'][:400_000]\n",
    "which_truncation = priors[name]['which_truncation']\n",
    "which_grid_point = priors[name]['which_grid_point']\n",
    "POIs = priors[name]['POI_indices']\n",
    "A = priors[name]['A']\n",
    "bounds = np.array(priors[name]['bounds_rounds'][which_grid_point][which_truncation])\n",
    "\n",
    "draws1d = {}\n",
    "draws2d = {}\n",
    "weights1d = {}\n",
    "weights2d = {}\n",
    "for rnd in range(0,1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    draws1d[round],draws2d[round],weights1d[round],weights2d[round] = draw_DRP_samples_fast(\n",
    "        priors[name]['net'][round]['grid_point_50'],\n",
    "        trainer,\n",
    "        samples,\n",
    "        prior_samples,\n",
    "        batch_size = 1024*64\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56910b62-856d-4583-b95c-9524bfa9f3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 14.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def test_DRP_values(tries=3,n_samps=1000, n_prior_samps=1000, n_refs=100, gridpoints = gridpoints):\n",
    "    name = names[0]\n",
    "    which_truncation = priors[name]['which_truncation']\n",
    "    which_grid_point = priors[name]['which_grid_point']\n",
    "    POIs = priors[name]['POI_indices']\n",
    "    A = priors[name]['A']\n",
    "    bounds = np.array(priors[name]['bounds_rounds'][which_grid_point][which_truncation])\n",
    "        \n",
    "    round = 'round_0'\n",
    "    validation_sums = {}\n",
    "    key = list(draws2d[round].keys())[0]\n",
    "    rows = len(POIs)\n",
    "    print('Computing references... ', flush=True, end=\"\")\n",
    "    references_2d = np.array([\n",
    "        references2D(samples)[0] for _ in range(n_refs)\n",
    "    ])\n",
    "    print('done.')\n",
    "    for gp in gridpoints:\n",
    "        print()\n",
    "        gridpoint = \"grid_point_\"+str(gp)\n",
    "        print('Gridpoint ' + str(gp))\n",
    "        validation_sums[gp] = np.zeros(tries)\n",
    "        \n",
    "        for trial in range(tries):\n",
    "\n",
    "            print('Computing trial '+str(trial)+\"... \", flush=True, end=\"\\r\")\n",
    "            \n",
    "            random_indices = random.sample(list(np.arange(len(samples))), n_samps)\n",
    "            random_prior_indices = random.sample(list(np.arange(len(prior_samples))), n_prior_samps)\n",
    "\n",
    "            draws = draws2d[round][key][random_prior_indices][:,random_indices,:]\n",
    "            weights = weights2d[round][key][random_prior_indices][:,random_indices]\n",
    "            truths = samples['params'][:,[0,1]][random_indices]\n",
    "            refs = references_2d[:,random_indices]\n",
    "            \n",
    "            validation_sum = 0\n",
    "            for ref_i in range(n_refs): \n",
    "                ecp_pp, alpha_pp, _, _, _,_,f_score,_ = get_drp_coverage_torch(\n",
    "                    draws,\n",
    "                    truths,\n",
    "                    weights=weights,\n",
    "                    theta_names=np.array(A.param_names)[[0,1]],\n",
    "                    bounds = np.array(bounds)[[0,1]],\n",
    "                    references = refs[ref_i,:],\n",
    "                    device='cuda',\n",
    "                    intermediate_figures=False,\n",
    "                )\n",
    "                validation_sum += f_score/n_refs\n",
    "            \n",
    "            validation_sums[gp][trial] = validation_sum\n",
    "            \n",
    "            # print(validation_sum)\n",
    "        print('Done.')\n",
    "        \n",
    "    return validation_sums\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe7d0275-90e8-4ff6-a5fc-1794d9dfca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_theoretical_f_stability(mock_bins=50,mock_n_per_bin=10, mock_n_ref=10_000, mock_tries=1):\n",
    "    mock_n = mock_bins*mock_n_per_bin \n",
    "    mock_alpha = np.linspace(0,1,mock_bins+1)[1:]\n",
    "    mock_dx = mock_alpha[1]-mock_alpha[0]\n",
    "    mock_upper = 1+3*mock_n_per_bin**(-0.5)\n",
    "    mock_lower = 1-3*mock_n_per_bin**(-0.5)\n",
    "    mock_uncertainty = (mock_upper-mock_lower)/2\n",
    "    mock_validation_sums = np.zeros((mock_tries,))\n",
    "    for trial in range(mock_tries):\n",
    "        print('Computing trial '+str(trial), flush=True, end='\\r')\n",
    "        mock_validation_sum = 0\n",
    "        for ref_i in range(mock_n_ref):\n",
    "            mock_f = np.random.uniform(size=(mock_n,))\n",
    "            mock_histogram = torch.histogram(torch.tensor(mock_f), density=True, bins=mock_bins ,range=(0,1))\n",
    "            mock_h = np.array(mock_histogram.hist)\n",
    "            mock_validation_sum += np.sum(((mock_h-1)/mock_uncertainty)**2)/(mock_n_ref*mock_bins)\n",
    "        mock_validation_sums[trial] = mock_validation_sum\n",
    "    print()\n",
    "    plt.hist(mock_validation_sums, density=True)\n",
    "\n",
    "    # print(mock_n)\n",
    "    # print(mock_alpha)\n",
    "    # print(mock_n_per_bin)\n",
    "    # print(mock_uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea4b35-521d-42da-9812-07d70c8c72a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing trial 999\n",
      "Computing trial 270\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.add_subplot(1,1,1)\n",
    "test_theoretical_f_stability(mock_bins=50, mock_n_ref=100, mock_tries=1000, mock_n_per_bin=20)\n",
    "test_theoretical_f_stability(mock_bins=50, mock_n_ref=1000, mock_tries=1000, mock_n_per_bin=20)\n",
    "test_theoretical_f_stability(mock_bins=50, mock_n_ref=10_000, mock_tries=1000, mock_n_per_bin=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991d0ace-9938-43fd-bcaa-31c524a8e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sums1 = test_DRP_values(tries = 5, n_samps=1000, n_refs=100, n_prior_samps=80_000, gridpoints=[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3be2c9-c3fb-4d4d-ad96-7a0ba35e25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sums1\n",
    "new_fig = copy.deepcopy(fig)\n",
    "for gp, gridpoint in enumerate([50]):\n",
    "    color = ['r','g'][gp]\n",
    "    for s in sums[gridpoint]:\n",
    "        new_fig.axes[0].axvline(s, color=color, linestyle=':')\n",
    "new_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c2261-7b73-4e15-9b0e-039f00c4b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sums2 = test_DRP_values(tries = 5, n_samps=1000, n_refs=1000, n_prior_samps=80_000, gridpoints=[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9846b082-7cf2-4ac6-8840-687851791ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sums2\n",
    "new_fig = copy.deepcopy(fig)\n",
    "for gp, gridpoint in enumerate([50]):\n",
    "    color = ['r','g'][gp]\n",
    "    for s in sums[gridpoint]:\n",
    "        new_fig.axes[0].axvline(s, color=color, linestyle=':')\n",
    "new_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b80ea-f4eb-48fa-bfb1-5b5c52708ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sums3 = test_DRP_values(tries = 5, n_samps=1000, n_refs=10_000, n_prior_samps=80_000, gridpoints=[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d44be6d-bb90-48b2-ba30-ed213dd6ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sums3\n",
    "new_fig = copy.deepcopy(fig)\n",
    "for gp, gridpoint in enumerate([50]):\n",
    "    color = ['r','g'][gp]\n",
    "    for s in sums[gridpoint]:\n",
    "        new_fig.axes[0].axvline(s, color=color, linestyle=':')\n",
    "new_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b31ad1-0d3a-4bfa-9ae6-ae443df5d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sums4 = test_DRP_values(tries = 5, n_samps=1000, n_refs=100, n_prior_samps=400_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ff3d5-b13d-4206-9fed-e19b7e969bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a09ed0-741f-49b2-b871-b394a4c723be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sums4\n",
    "new_fig = copy.deepcopy(fig)\n",
    "for gp, gridpoint in enumerate(gridpoints):\n",
    "    color = ['r','g'][gp]\n",
    "    for s in sums[gridpoint]:\n",
    "        new_fig.axes[0].axvline(s, color=color, linestyle=':')\n",
    "new_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d43aa8-a984-4205-af0d-2225b526f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sums5 = test_DRP_values(tries = 5, n_samps=1000, n_refs=1_000, n_prior_samps=400_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697f17fa-93d2-4349-9ecf-8c898c172687",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sums5\n",
    "new_fig = copy.deepcopy(fig)\n",
    "for gp, gridpoint in enumerate(gridpoints):\n",
    "    color = ['r','g'][gp]\n",
    "    for s in sums[gridpoint]:\n",
    "        new_fig.axes[0].axvline(s, color=color, linestyle=':')\n",
    "new_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279a1b1-d9b5-4ec4-8dfc-671915bb5d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sums6 = test_DRP_values(tries = 5, n_samps=1000, n_refs=10_000, n_prior_samps=400_00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f27efe-30c9-4e1a-adfb-41fcdc1f7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = sums6\n",
    "new_fig = copy.deepcopy(fig)\n",
    "for gp, gridpoint in enumerate(gridpoints):\n",
    "    color = ['r','g'][gp]\n",
    "    for s in sums[gridpoint]:\n",
    "        new_fig.axes[0].axvline(s, color=color, linestyle=':')\n",
    "new_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8bde2-743e-40ef-a66d-b28a5a503d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fecb4a-9c51-4a3e-b9de-d16ed5bb1d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
