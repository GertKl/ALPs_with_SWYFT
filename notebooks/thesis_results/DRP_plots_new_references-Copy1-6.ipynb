{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7885c4b0-ccb2-49d9-b298-9fd9b7a9c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import swyft\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import importlib\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device_notebook = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import wandb\n",
    "import copy\n",
    "from torch.multiprocessing import Pool\n",
    "torch.multiprocessing.set_start_method('spawn',force=True)\n",
    "torch.set_num_threads(28)\n",
    "import itertools\n",
    "import subprocess\n",
    "from tqdm.auto import tqdm\n",
    "sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n",
    "from explim_functions import generate_expected_limits\n",
    "import sympy as sy\n",
    "from scipy.stats import norm, lognorm\n",
    "stdnorm = norm()\n",
    "from swyft.plot.mass import _get_jefferys_interval as interval\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56feaf19-6395-4d74-a1ff-6d089c02f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"ALPs_with_SWYFT\"\n",
    "thesis_figs = os.getcwd().split(main_dir)[0]+\"/\"+main_dir+\"/thesis_figures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875729e6-31ab-4306-bc54-618e6d81cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "names = ['flare0_informed',]\n",
    "colors_priors = ['r','#FFA500','y','g','b', ]\n",
    "\n",
    "priors = {}\n",
    "for ip, name in enumerate(names):\n",
    "\n",
    "    priors[name] = {'name': name}\n",
    "\n",
    "    priors[name]['results_path'] = '/home/gertwk/ALPs_with_SWYFT/cluster_runs/analysis_results/'+name\n",
    "\n",
    "    priors[name]['store_path'] = priors[name]['results_path']+\"/sim_output/store\"\n",
    "\n",
    "    priors[name]['config_vars'] = priors[name]['results_path'] +'/config_variables.pickle'\n",
    "\n",
    "    priors[name]['config_phys'] = priors[name]['results_path'] +'/physics_variables.pickle'\n",
    "    \n",
    "    priors[name]['truncation_record'] = priors[name]['results_path'] +'/truncation_record.pickle'\n",
    "\n",
    "    removed_ALP_sim=0\n",
    "    try:\n",
    "        sys.path.remove('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n",
    "        removed_ALP_sim=1\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        del sys.modules['ALP_quick_sim']\n",
    "    except KeyError:\n",
    "        pass\n",
    "    sys.path.append(priors[name]['results_path'])\n",
    "    import param_function\n",
    "    import ALP_quick_sim\n",
    "    with open(priors[name]['config_vars'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    with open(priors[name]['config_phys'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    with open(priors[name]['truncation_record'], 'rb') as file: config_objects = pickle.load(file)\n",
    "    for key in config_objects.keys(): priors[name][key] = config_objects[key]\n",
    "    sys.path.remove(priors[name]['results_path'])\n",
    "    sys.path.append(priors[name]['results_path']+'/train_output/net')\n",
    "    import network\n",
    "    sys.path.remove(priors[name]['results_path']+'/train_output/net')\n",
    "    \n",
    "    count = 0\n",
    "    for combo in itertools.product(*priors[name]['hyperparams'].values()):\n",
    "        if count == priors[name]['which_grid_point']:\n",
    "            hyperparams_point = {}\n",
    "            for i, key in enumerate(priors[name]['hyperparams'].keys()):\n",
    "                hyperparams_point[key]=combo[i]\n",
    "        count +=1\n",
    "\n",
    "    priors[name]['net_path'] = {}\n",
    "    priors[name]['net'] = {}\n",
    "    for rnd in range(priors[name]['which_truncation']+1):\n",
    "        round = 'round_'+str(rnd)\n",
    "        priors[name]['net_path'][round] = (priors[name]['results_path'] + '/train_output/net/trained_network_'\n",
    "                                                         +round+'_gridpoint_'+str(priors[name]['which_grid_point'])+'.pt')\n",
    "        priors[name]['net'][round] = network.NetworkCorner(\n",
    "            nbins=priors[name]['A'].nbins,\n",
    "            marginals=priors[name]['POI_indices'],\n",
    "            param_names=priors[name]['A'].param_names,\n",
    "            **hyperparams_point,\n",
    "        )\n",
    "        priors[name]['net'][round].load_state_dict(torch.load(priors[name]['net_path'][round]))\n",
    "\n",
    "    with open(priors[name]['results_path']+'/explim_predictions.pickle', 'rb') as file:\n",
    "        priors[name]['predictions'] = pickle.load(file)\n",
    "\n",
    "    if priors[name]['which_truncation'] > 0:\n",
    "        store = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "        store_explim = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_explim_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "        store_prior = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_prior_round_\"+str(priors[name]['which_truncation'])+\"_gridpoint_\"+str(priors[name]['which_grid_point']))\n",
    "    else:\n",
    "        store = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name'])\n",
    "        store_explim = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_explim\")\n",
    "        store_prior = swyft.ZarrStore(priors[name]['store_path'] + \"/\" + priors[name]['store_name']+\"_prior\")\n",
    "    priors[name]['samples'] = store.get_sample_store()\n",
    "    priors[name]['samples_explim'] = store_explim.get_sample_store()\n",
    "    priors[name]['samples_prior'] = store_prior.get_sample_store()\n",
    " \n",
    "    del sys.modules['param_function']\n",
    "    del sys.modules['ALP_quick_sim']\n",
    "    del sys.modules['network']\n",
    "    if removed_ALP_sim: sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339b4fe7-b2bd-4a4c-be5c-01cafebeb8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gertwk/.conda/envs/swyft4-dev-notebook/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/gertwk/.conda/envs/swyft4-dev-notebook/lib/pyt ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = swyft.SwyftTrainer(accelerator = 'cuda', precision = 64,logger=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb27e054-6bab-4c12-8d90-1374bf989d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/gertwk/ALPs_with_SWYFT/analysis_scripts/ALP_sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7af9786-3a1b-4247-a172-23c26ce443ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pair_to_index(pair,n_indices):\n",
    "    pair = sorted(pair)\n",
    "    return int((pair[0]+1)*(n_indices-1+n_indices-pair[0]-1)/2 - n_indices + pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a6d358e-2538-4bdf-883a-2da94cb5165d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(exp,n_bins):\n",
    "    x = np.linspace(-1,1,n_bins)\n",
    "    return 0.5+0.5*np.cos(np.pi*np.sign(x)*np.abs(x)**exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ad26aa-af63-489c-82c7-791186d96dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(color1, color2, amount=0.5):\n",
    "    return tuple(np.array(color1)*amount + np.array(color2)*(1-amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e74571-219a-4416-a305-c876e5effe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_to_z(x):\n",
    "    return stdnorm.ppf(0.5+x/2)\n",
    "\n",
    "def z_to_p(x):\n",
    "    return stdnorm.cdf(x)-stdnorm.cdf(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4430502f-9e21-4f1c-a073-e11163d93372",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del sys.modules['DRP_test']\n",
    "except KeyError:\n",
    "    pass\n",
    "try:\n",
    "    del sys.modules['reference_functions']\n",
    "except KeyError:\n",
    "    pass\n",
    "from DRP_test import get_drp_coverage, get_drp_coverage_torch, draw_DRP_samples_fast\n",
    "from reference_functions import References\n",
    "R = References()\n",
    "references2D = R.references2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ffee245-bc1d-4bf8-813a-e14cefc08c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_colors = ['r','y','g','b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c40b8f-a4ee-4065-a192-dd18cd9d36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_location = '/storage/gertwk/ALPs_with_SWYFT/notebooks/thesis_results'\n",
    "storage_identifier = 'DRP_plots_new_references-Copy1-6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e0d725-460b-4143-87e1-38fd6bd35e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.2 ms, sys: 0 ns, total: 27.2 ms\n",
      "Wall time: 223 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_samps = 500_000\n",
    "n_prior_samps=20_173\n",
    "n_refs = 100\n",
    "which_truncation = 3\n",
    "\n",
    "name = names[0]\n",
    "samples = priors[name]['samples'][-n_samps:]\n",
    "prior_samples = priors[name]['samples_prior'][:n_prior_samps]\n",
    "which_truncation = priors[name]['which_truncation']\n",
    "which_grid_point = priors[name]['which_grid_point']\n",
    "POIs = priors[name]['POI_indices']\n",
    "A = priors[name]['A']\n",
    "bounds = np.array(priors[name]['bounds_rounds'][which_grid_point][which_truncation])\n",
    "len_samps = len(samples)\n",
    "len_prior_samps = len(prior_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbc200e5-a768-457a-9983-26e706f7192c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36d54f3a6fd469eb7e20f3846c437b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:8\u001b[0m\n",
      "File \u001b[0;32m~/ALPs_with_SWYFT/analysis_scripts/ALP_sim/DRP_test.py:455\u001b[0m, in \u001b[0;36mdraw_DRP_samples_fast\u001b[0;34m(net, trainer, samples, prior_samples, batch_size)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_DRP_samples_fast\u001b[39m(\n\u001b[1;32m    447\u001b[0m         net,\n\u001b[1;32m    448\u001b[0m         trainer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m    452\u001b[0m         ):\n\u001b[1;32m    454\u001b[0m         repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(prior_samples) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mlen\u001b[39m(prior_samples) \u001b[38;5;241m%\u001b[39m batch_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 455\u001b[0m         logratios1d, logratios2d \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrepeat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprior_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m         draws1d \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    462\u001b[0m         draws2d \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/ALPs_with_SWYFT/swyft/swyft/lightning/core.py:318\u001b[0m, in \u001b[0;36mSwyftTrainer.infer\u001b[0;34m(self, model, A, B, return_sample_ratios, batch_size)\u001b[0m\n\u001b[1;32m    316\u001b[0m ratio_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(model, dl)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_sample_ratios:\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mratio_batches\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    319\u001b[0m         keys \u001b[38;5;241m=\u001b[39m ratio_batches[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    320\u001b[0m         d \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    321\u001b[0m             k: LogRatioSamples(\n\u001b[1;32m    322\u001b[0m                 torch\u001b[38;5;241m.\u001b[39mcat([r[k]\u001b[38;5;241m.\u001b[39mlogratios \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m ratio_batches]),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m k[:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maux_\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    328\u001b[0m         }\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "overwrite_DRP_storage = 0\n",
    "if not os.path.exists(storage_location+'/'+storage_identifier): os.mkdir(storage_location+'/'+storage_identifier)\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    filename = storage_location+'/'+storage_identifier+'/DRP_samples_'+str(len_samps)+'_'+str(len_prior_samps)+'_'+round\n",
    "    if not os.path.exists(filename) or overwrite_DRP_storage:\n",
    "        DRP_coverage_samples = {}\n",
    "        DRP_coverage_samples['draws1d'],DRP_coverage_samples['draws2d'],DRP_coverage_samples['weights1d'],DRP_coverage_samples['weights2d'] = draw_DRP_samples_fast(\n",
    "            priors[name]['net'][round],\n",
    "            trainer,\n",
    "            samples,\n",
    "            prior_samples,\n",
    "            batch_size = 1024*4,\n",
    "        )\n",
    "        with open(filename,'wb') as file: pickle.dump(DRP_coverage_samples,file)  \n",
    "        del DRP_coverage_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9afd355-fb38-4653-8deb-d0b675dd3205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This estimates the mass of highest-likelihood intervals.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fec897c2f8409698926b461eca94c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "overwrite_HPD_storage = 0\n",
    "if not os.path.exists(storage_location+'/'+storage_identifier): os.mkdir(storage_location+'/'+storage_identifier)\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    filename = storage_location+'/'+storage_identifier+'/HPD_samples_'+str(len_samps)+'_'+str(len_prior_samps)+'_'+round\n",
    "    if not os.path.exists(filename) or overwrite_HPD_storage:\n",
    "        HPD_coverage_samples = trainer.test_coverage(priors[name]['net'][round], samples, prior_samples)\n",
    "        with open(filename,'wb') as file: pickle.dump(HPD_coverage_samples,file)  \n",
    "        del HPD_coverage_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcc01d-f07c-433e-8e1f-2a3c66ecfe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "references_1d = [\n",
    "    references2D(samples)[0][:,[0]] for _ in range(n_refs)\n",
    "]\n",
    "\n",
    "references_2d = [\n",
    "    references2D(samples)[0] for _ in range(n_refs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e7ab2-0ce8-4bb7-8e40-2c5eb55cfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "overwrite_DRP_draws = 0\n",
    "\n",
    "ecp_pp = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "alpha_pp = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "ecp_zz = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "alpha_zz = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "f_pp = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "f_zz = { 'round_'+str(rnd) : [[{} for ref_list in references_1d],[{} for ref_list in references_2d]] for rnd in range(which_truncation+1) }\n",
    "validation_sums = { 'round_'+str(rnd) : [{},{}] for rnd in range(which_truncation+1) }\n",
    "rows = len(POIs)\n",
    "\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    len_samps = len(samples)\n",
    "    len_prior_samps = len(prior_samples)\n",
    "    filename = storage_location+'/'+storage_identifier+'/DRP_samples_'+str(len_samps)+'_'+str(len_prior_samps)+'_'+round\n",
    "    with open(filename,'rb') as file: coverage_samples = pickle.load(file)\n",
    "    keys_1d = list(coverage_samples['draws1d'].keys())\n",
    "    keys_2d = list(coverage_samples['draws2d'].keys())\n",
    "    filename_draws = storage_location+'/'+storage_identifier+'/DRP_draws_'+str(len_samps)+'_'+str(len_prior_samps)+'_'+round\n",
    "\n",
    "    \n",
    "    if os.path.exists(filename_draws) and not overwrite_DRP_draws: \n",
    "        with open(filename_draws,'rb') as file: DRP_draws = pickle.load(file)\n",
    "        ecp_pp[round] = DRP_draws['ecp_pp']\n",
    "        ecp_zz[round] = DRP_draws['ecp_zz']\n",
    "        alpha_pp[round] = DRP_draws['alpha_pp']\n",
    "        alpha_zz[round] = DRP_draws['alpha_zz']\n",
    "        f_pp[round] = DRP_draws['f_pp']\n",
    "        f_zz[round] = DRP_draws['f_zz']\n",
    "        validation_sums[round] = DRP_draws['f_score']\n",
    "    else:\n",
    "        for i, key in enumerate(keys_1d):\n",
    "            draws = coverage_samples['draws1d'][key]\n",
    "            samps = samples['params'][:,[POIs[i]]]\n",
    "            weights = coverage_samples['weights1d'][key]\n",
    "            \n",
    "            for ref_i in range(len(references_1d)):\n",
    "                random_indices = random.sample(list(np.arange(len(samples))), n_samps)\n",
    "                random_prior_indices = random.sample(list(np.arange(len(prior_samples))), n_prior_samps)\n",
    "        \n",
    "                ecp_pp[round][0][ref_i][key], alpha_pp[round][0][ref_i][key], ecp_zz[round][0][ref_i][key], alpha_zz[round][0][ref_i][key], f_pp[round][0][ref_i][key], f_zz[round][0][ref_i][key], f_score, _ = get_drp_coverage_torch(\n",
    "                    draws[random_prior_indices][:,random_indices,:],\n",
    "                    samps[random_indices],\n",
    "                    weights = weights[random_prior_indices][:,random_indices],\n",
    "                    theta_names=A.param_names[POIs[i]],\n",
    "                    bounds = np.array(bounds)[[POIs[i]]],\n",
    "                    references = references_1d[ref_i][random_indices],\n",
    "                    device='cuda',\n",
    "                    intermediate_figures=False,\n",
    "                )\n",
    "    \n",
    "                if ref_i == 0: validation_sums[round][0][key] = 0\n",
    "                validation_sums[round][0][key] += f_score/n_refs\n",
    "                \n",
    "        row = 0\n",
    "        column = 0\n",
    "        for i, key in enumerate(keys_2d):\n",
    "            row+=1\n",
    "            if row >= rows:\n",
    "                column+=1\n",
    "                row = 1+column  \n",
    "        \n",
    "            draws = coverage_samples['draws2d'][key]\n",
    "            samps = samples['params'][:,[column,row]]\n",
    "            weights = coverage_samples['weights2d'][key]\n",
    "        \n",
    "            for ref_i in range(len(references_2d)): \n",
    "                random_indices = random.sample(list(np.arange(len(samples))), n_samps)\n",
    "                random_prior_indices = random.sample(list(np.arange(len(prior_samples))), n_prior_samps)\n",
    "            \n",
    "                ecp_pp[round][1][ref_i][key], alpha_pp[round][1][ref_i][key], ecp_zz[round][1][ref_i][key], alpha_zz[round][1][ref_i][key], f_pp[round][1][ref_i][key],f_zz[round][0][ref_i][key], f_score, _ = get_drp_coverage_torch(\n",
    "                    draws[random_prior_indices][:,random_indices,:],\n",
    "                    samps[random_indices],\n",
    "                    weights = weights[random_prior_indices][:,random_indices],\n",
    "                    theta_names=np.array(A.param_names)[[column,row]],\n",
    "                    bounds = np.array(bounds)[[column,row]],\n",
    "                    references = references_2d[ref_i][random_indices],\n",
    "                    device='cuda',\n",
    "                    intermediate_figures=False,\n",
    "                )\n",
    "    \n",
    "                if ref_i == 0: validation_sums[round][1][key] = 0\n",
    "                validation_sums[round][1][key] += f_score/n_refs\n",
    "\n",
    "        DRP_draws = {\n",
    "            'ecp_pp': ecp_pp[round],\n",
    "            'ecp_zz': ecp_zz[round],\n",
    "            'alpha_pp': alpha_pp[round],\n",
    "            'alpha_zz': alpha_zz[round],\n",
    "            'f_pp': f_pp[round],\n",
    "            'f_zz': f_zz[round],\n",
    "            'f_score': validation_sums[round],\n",
    "        }\n",
    "        with open(filename_draws,'wb') as file: pickle.dump(DRP_draws,file)\n",
    "\n",
    "for i, key in enumerate(keys_1d):\n",
    "    print(key)\n",
    "    for rnd in range(which_truncation+1):\n",
    "        print(validation_sums['round_'+str(rnd)][0][key])\n",
    "    print()\n",
    "\n",
    "for i, key in enumerate(keys_2d):\n",
    "    print(key)\n",
    "    for rnd in range(which_truncation+1):\n",
    "        print(validation_sums['round_'+str(rnd)][1][key])\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3902a1-2e1a-4bf0-b07f-7cdb61c94903",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# CONFIGURATION\n",
    "label_size = 15\n",
    "label_pad = 0\n",
    "tick_size = 10\n",
    "x_tick_pad = 1\n",
    "y_tick_pad = -1\n",
    "x_tick_rotation = 45\n",
    "y_tick_rotation = 45\n",
    "max_y_ticks = 4\n",
    "max_z =3\n",
    "significance1 = 5/n_samps\n",
    "significance2 = 1/n_samps\n",
    "blend_amount = 0.5\n",
    "opacity = 0.25\n",
    "HPD_residuals = True\n",
    "legend_loc = (0,2.1)\n",
    "\n",
    "automatic_rel_ticks = True\n",
    "\n",
    "x_axis_pp = \"$1-\\\\alpha$\"\n",
    "y_axis_pp = 'EC' #\"$\\mathrm{ECP}$\"\n",
    "ticks_pp = [0.5,0.68,0.95]\n",
    "\n",
    "x_axis_zz = \"$Z_{1-\\\\alpha}$\"\n",
    "y_axis_zz = \"$Z_\\mathrm{EC}$\"\n",
    "ticks_zz = [1,2,3]\n",
    "\n",
    "x_axis_rel = \"$1-\\\\alpha$\"\n",
    "y_axis_rel = \"$\\mathrm{EC}$ residuals\"\n",
    "x_ticks_rel = ticks_pp\n",
    "y_ticks_rel = [-0.1,1,0.1]\n",
    "\n",
    "x_axis_rel_zz = \"$Z_{1-\\\\alpha}$\"\n",
    "y_axis_rel_zz = \"$Z_\\mathrm{EC}$ residuals\"\n",
    "x_ticks_rel_zz = ticks_zz\n",
    "y_ticks_rel_zz = [-1,0,1]\n",
    "\n",
    "POI_names = ['$m_a$', '$g_{a \\\\gamma}$', 'Spectral Amplitude', 'Spectral Index', 'Cut-off Energy']\n",
    "\n",
    "x_axis_list = [x_axis_pp,x_axis_zz,x_axis_rel,x_axis_rel_zz,x_axis_pp,x_axis_zz]\n",
    "y_axis_list = [y_axis_pp,y_axis_zz,y_axis_rel,y_axis_rel_zz,y_axis_pp,y_axis_zz]\n",
    "x_tick_list = [ticks_pp,ticks_zz,ticks_pp,ticks_zz,ticks_pp,ticks_zz]\n",
    "\n",
    "if not HPD_residuals:\n",
    "    y_tick_list = [ticks_pp,ticks_zz,y_ticks_rel,y_ticks_rel_zz,y_ticks_rel,y_ticks_rel_zz]\n",
    "else:\n",
    "    y_tick_list = [ticks_pp,ticks_zz,y_ticks_rel,y_ticks_rel_zz,x_ticks_rel,x_ticks_rel_zz]\n",
    "\n",
    "adjusted_colors = [blend(to_rgb(col),(1,1,1),amount=blend_amount) for col in round_colors[:-1]]\n",
    "adjusted_colors.append(round_colors[-1])\n",
    "\n",
    "rows = len(POIs)\n",
    "\n",
    "\n",
    "DRP_fig_pp = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_zz = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_rel = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_rel_zz = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_HPD_pp = plt.figure(figsize = (12, 12))\n",
    "DRP_fig_HPD_zz = plt.figure(figsize = (12, 12))\n",
    "\n",
    "fig_list = [DRP_fig_pp,DRP_fig_zz,DRP_fig_rel,DRP_fig_rel_zz, DRP_fig_HPD_pp,DRP_fig_HPD_zz]\n",
    "\n",
    "\n",
    "DRP_fig_pp.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "DRP_fig_zz.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "DRP_fig_rel.subplots_adjust(hspace=0.1, wspace=0.25)\n",
    "DRP_fig_rel_zz.subplots_adjust(hspace=0.1, wspace=0.25)\n",
    "if HPD_residuals:\n",
    "    DRP_fig_HPD_pp.subplots_adjust(hspace=0.1, wspace=0.25)\n",
    "    DRP_fig_HPD_zz.subplots_adjust(hspace=0.1, wspace=0.25)\n",
    "else:\n",
    "    DRP_fig_HPD_pp.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "    DRP_fig_HPD_zz.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "#LOADING HPD COVERAGE SAMPLES\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    filename = storage_location+'/'+storage_identifier+'/HPD_samples_'+str(len_samps)+'_'+str(len_prior_samps)+'_'+round\n",
    "    with open(filename,'rb') as file: coverage_samples[round] = pickle.load(file)\n",
    "\n",
    "#ITERATION OVER FIGURES AND SUBFIGURES\n",
    "row = -1\n",
    "column = 0\n",
    "index_1d=-1\n",
    "index_2d=-1\n",
    "make_extra_plot = False\n",
    "gs = gridspec.GridSpec(5,5)\n",
    "i = -1\n",
    "while i < len(keys_1d)+len(keys_2d)-1:\n",
    "    i+=1\n",
    "    if not make_extra_plot:\n",
    "        row+=1\n",
    "        if row == rows:\n",
    "            column+=1\n",
    "            row = column\n",
    "        if row == column:\n",
    "            dims = 0\n",
    "            index_1d += 1\n",
    "            key = keys_1d[index_1d]\n",
    "        else:\n",
    "            dims = 1\n",
    "            index_2d += 1\n",
    "            key = keys_2d[index_2d]\n",
    "\n",
    "        for fig_i, fig in enumerate(fig_list): fig.add_subplot(rows, rows, rows*row+column+1)\n",
    "            \n",
    "    else:\n",
    "        for fig_i, fig in enumerate(fig_list): fig.add_subplot(gs[:-3,3:])\n",
    "\n",
    "    print(str(i)+'/'+str(len(keys_1d)+len(keys_2d))+' ('+str(row)+','+str(column)+')',flush=True,end='\\r')\n",
    "\n",
    "    # PLOTTING OF COVERAGES\n",
    "    \n",
    "    for rnd in range(which_truncation+1):\n",
    "        round = 'round_'+str(rnd)\n",
    "        for ref_i in range(len(references_2d)):\n",
    "            ecp_ex_pp = np.zeros(len(ecp_pp[round][dims][ref_i][key])+1)\n",
    "            alpha_ex_pp = np.zeros(len(alpha_pp[round][dims][ref_i][key])+1)\n",
    "            ecp_ex_zz = np.zeros(len(ecp_zz[round][dims][ref_i][key])+1)\n",
    "            alpha_ex_zz_orig = np.zeros(len(alpha_zz[round][dims][ref_i][key])+1)\n",
    "            ecp_ex_pp[1:] = ecp_pp[round][dims][ref_i][key]\n",
    "            alpha_ex_pp[1:] = alpha_pp[round][dims][ref_i][key]\n",
    "            ecp_ex_zz[1:] = ecp_zz[round][dims][ref_i][key]\n",
    "            alpha_ex_zz_orig[1:] = alpha_zz[round][dims][ref_i][key]\n",
    "            alpha_ex_zz = alpha_ex_zz_orig[alpha_ex_zz_orig<=max_z]\n",
    "            ecp_ex_zz = ecp_ex_zz[alpha_ex_zz_orig<=max_z]\n",
    "            if rnd < which_truncation:\n",
    "                label = 'Range after truncation #' + str(rnd) if ref_i == 0 else None\n",
    "                DRP_fig_pp.axes[-1].fill_between(alpha_ex_pp,ecp_ex_pp,alpha_ex_pp, color=adjusted_colors[rnd],label=label)\n",
    "                DRP_fig_zz.axes[-1].fill_between(alpha_ex_zz,ecp_ex_zz,alpha_ex_zz, color=adjusted_colors[rnd],label=label)\n",
    "                DRP_fig_rel.axes[-1].fill_between(alpha_ex_pp,(ecp_ex_pp-alpha_ex_pp),np.zeros(len(alpha_ex_pp)), color=adjusted_colors[rnd],label=label)\n",
    "                DRP_fig_rel_zz.axes[-1].fill_between(alpha_ex_zz,(ecp_ex_zz-alpha_ex_zz),np.zeros(len(alpha_ex_zz)), color=adjusted_colors[rnd],label=label)  \n",
    "            else:\n",
    "                label = 'Final coverages' if ref_i == 0 else None\n",
    "                DRP_fig_pp.axes[-1].plot(alpha_ex_pp, ecp_ex_pp, round_colors[rnd],alpha=opacity,label=label)\n",
    "                DRP_fig_zz.axes[-1].plot(alpha_ex_zz, ecp_ex_zz, round_colors[rnd],alpha=opacity,label=label)\n",
    "                DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (ecp_ex_pp-alpha_ex_pp), round_colors[rnd],alpha=opacity,label=label)\n",
    "                DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (ecp_ex_zz-alpha_ex_zz), round_colors[rnd],alpha=opacity,label=label)\n",
    "        label = 'Coverage with error after truncation #' + str(rnd)\n",
    "        if dims == 0:\n",
    "            swyft.plot_pp(coverage_samples[round], key,ax = DRP_fig_HPD_pp.axes[-1],color=adjusted_colors[rnd],interval_opacity=0.25,label=label,interval_label=None,x_label=None,y_label=None,diagonal_color=None,residuals=True)\n",
    "            swyft.plot_zz(coverage_samples[round], key,ax = DRP_fig_HPD_zz.axes[-1],color=adjusted_colors[rnd],interval_opacity=0.25,sigma_color=None,label=label,interval_label=None,x_label=None,y_label=None,diagonal_color=None,residuals=True,z_max=max_z)\n",
    "        else:\n",
    "            swyft.plot_pp(coverage_samples[round], eval(key.replace(' ',',')),ax = DRP_fig_HPD_pp.axes[-1],color=adjusted_colors[rnd],interval_opacity=0.25,label=label,interval_label=None,x_label=None,y_label=None,diagonal_color=None,residuals=HPD_residuals)\n",
    "            swyft.plot_zz(coverage_samples[round], eval(key.replace(' ',',')),ax = DRP_fig_HPD_zz.axes[-1],color=adjusted_colors[rnd],interval_opacity=0.25,sigma_color=None,label=label,interval_label=None,x_label=None,y_label=None,diagonal_color=None,residuals=HPD_residuals,z_max=max_z)\n",
    "    \n",
    "    \n",
    "    #CONFIGURATION OF INDIVIDUAL AXES\n",
    "    \n",
    "    for fig_i, fig in enumerate(fig_list): \n",
    "        fig.axes[-1].set_xticks(x_tick_list[fig_i])\n",
    "        fig.axes[-1].set_xticklabels([])\n",
    "        fig.axes[-1].set_yticks(y_tick_list[fig_i])\n",
    "        fig.axes[-1].set_yticklabels([])\n",
    "\n",
    "    if automatic_rel_ticks:\n",
    "        DRP_fig_rel.axes[-1].yaxis.set_major_locator(MaxNLocator(nbins=max_y_ticks))\n",
    "        DRP_fig_rel_zz.axes[-1].yaxis.set_major_locator(MaxNLocator(nbins=max_y_ticks))\n",
    "        DRP_fig_HPD_pp.axes[-1].yaxis.set_major_locator(MaxNLocator(nbins=max_y_ticks))\n",
    "        DRP_fig_HPD_zz.axes[-1].yaxis.set_major_locator(MaxNLocator(nbins=max_y_ticks))\n",
    "\n",
    "        DRP_fig_rel.axes[-1].yaxis.set_major_formatter(plt.ScalarFormatter(None))\n",
    "        DRP_fig_rel_zz.axes[-1].yaxis.set_major_formatter(plt.ScalarFormatter(None))\n",
    "        DRP_fig_HPD_pp.axes[-1].yaxis.set_major_formatter(plt.ScalarFormatter(None))\n",
    "        DRP_fig_HPD_zz.axes[-1].yaxis.set_major_formatter(plt.ScalarFormatter(None))\n",
    "\n",
    "        DRP_fig_pp.axes[-1].set_yticks(ticks_pp)\n",
    "        DRP_fig_zz.axes[-1].set_yticks(ticks_zz)\n",
    "        \n",
    "    if row==column:\n",
    "        for fig_i, fig in enumerate(fig_list): fig.axes[-1].set_title(POI_names[row])\n",
    "  \n",
    "    if row==rows-1:\n",
    "        for fig_i, fig in enumerate(fig_list): \n",
    "            fig.axes[-1].tick_params(axis='x',labelsize=tick_size,pad=x_tick_pad,rotation=x_tick_rotation)\n",
    "            # fig.axes[-1].set_xticks(x_tick_list[fig_i])\n",
    "            fig.axes[-1].set_xticklabels(x_tick_list[fig_i])\n",
    "            fig.axes[-1].set_xlabel(x_axis_list[fig_i], fontsize=label_size, labelpad=label_pad)\n",
    "        \n",
    "    if column == 0:\n",
    "        DRP_fig_pp.axes[-1].set_yticklabels(ticks_pp)\n",
    "        DRP_fig_zz.axes[-1].set_yticklabels(ticks_zz)\n",
    "        for fig_i, fig in enumerate(fig_list): \n",
    "            fig.axes[-1].set_ylabel(y_axis_list[fig_i], fontsize=label_size, labelpad=label_pad)\n",
    "            if not automatic_rel_ticks: fig.axes[-1].set_yticklabels(y_tick_list[fig_i])\n",
    "            \n",
    "    for fig_i, fig in enumerate(fig_list):\n",
    "        fig.axes[-1].tick_params(axis='y',labelsize=tick_size,rotation=y_tick_rotation, pad=y_tick_pad)\n",
    "\n",
    "    uncertainty1 = interval((alpha_ex_pp*n_samps).astype(int),n_samps,alpha = significance1)\n",
    "    upper_uncertainty1 = uncertainty1[:,0]\n",
    "    lower_uncertainty1 = uncertainty1[:,1]\n",
    "    uncertainty2 = interval((alpha_ex_pp*n_samps).astype(int),n_samps,alpha = significance2)\n",
    "    upper_uncertainty2 = uncertainty2[:,0]\n",
    "    lower_uncertainty2 = uncertainty2[:,1]\n",
    "    uncertainty1_zz = interval((z_to_p(alpha_ex_zz)*n_samps).astype(int),n_samps,alpha=significance1)\n",
    "    upper_uncertainty1_zz = p_to_z(uncertainty1_zz[:,1])\n",
    "    lower_uncertainty1_zz = p_to_z(uncertainty1_zz[:,0])\n",
    "    uncertainty2_zz = interval((z_to_p(alpha_ex_zz)*n_samps).astype(int),n_samps,alpha=significance2)\n",
    "    upper_uncertainty2_zz = p_to_z(uncertainty2_zz[:,1])\n",
    "    lower_uncertainty2_zz = p_to_z(uncertainty2_zz[:,0])\n",
    "\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, alpha_ex_pp,'k-',label='$ECP=1-\\\\alpha$')\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, upper_uncertainty1,'k--', label='Significance = {:1g}'.format(significance1))\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, lower_uncertainty1,'k--')\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, upper_uncertainty2,'k:', label='Significance = {:1g}'.format(significance2))\n",
    "    DRP_fig_pp.axes[-1].plot(alpha_ex_pp, lower_uncertainty2,'k:')\n",
    "\n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (alpha_ex_pp-alpha_ex_pp), 'k-',label='$ECP=1-\\\\alpha$')\n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (upper_uncertainty1-alpha_ex_pp), 'k--',label='Significance '+str(significance1))\n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (lower_uncertainty1-alpha_ex_pp), 'k--')\n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (upper_uncertainty2-alpha_ex_pp), 'k:',label='Significance '+str(significance2))\n",
    "    DRP_fig_rel.axes[-1].plot(alpha_ex_pp, (lower_uncertainty2-alpha_ex_pp), 'k:')\n",
    "\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, alpha_ex_zz, 'k-',label='$ECP=1-\\\\alpha$')\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, upper_uncertainty1_zz,'k--',label='Significance = {:1g}'.format(significance1))\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, lower_uncertainty1_zz,'k--')\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, upper_uncertainty2_zz,'k:',label='Significance = {:1g}'.format(significance2))\n",
    "    DRP_fig_zz.axes[-1].plot(alpha_ex_zz, lower_uncertainty2_zz,'k:')\n",
    "    # DRP_fig_zz.axes[-1].set_ylim([0,max_z+1])\n",
    "    \n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (alpha_ex_zz-alpha_ex_zz), 'k-',label='$ECP=1-\\\\alpha$')\n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (upper_uncertainty1_zz-alpha_ex_zz), 'k--',label='Significance = {:1g}'.format(significance1))\n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (lower_uncertainty1_zz-alpha_ex_zz), 'k--')\n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (upper_uncertainty2_zz-alpha_ex_zz), 'k:',label='Significance = {:1g}'.format(significance2))\n",
    "    DRP_fig_rel_zz.axes[-1].plot(alpha_ex_zz, (lower_uncertainty2_zz-alpha_ex_zz), 'k:')\n",
    "    # DRP_fig_rel_zz.axes[-1].set_ylim([-0.5*max_z,0.5*max_z])\n",
    "  \n",
    "    if HPD_residuals:\n",
    "        DRP_fig_HPD_pp.axes[-1].plot(alpha_ex_pp, (alpha_ex_pp-alpha_ex_pp), 'k-',label='$ECP=1-\\\\alpha$')\n",
    "        DRP_fig_HPD_zz.axes[-1].plot(alpha_ex_zz, (alpha_ex_zz-alpha_ex_zz), 'k-',label='$ECP=1-\\\\alpha$')\n",
    "        DRP_fig_HPD_zz.axes[-1].set_ylim([-0.5*max_z,0.5*max_z])\n",
    "    else:\n",
    "        DRP_fig_HPD_pp.axes[-1].plot(alpha_ex_pp, alpha_ex_pp, 'k-',label='$ECP=1-\\\\alpha$')\n",
    "        DRP_fig_HPD_zz.axes[-1].plot(alpha_ex_zz, alpha_ex_zz, 'k-',label='$ECP=1-\\\\alpha$')\n",
    "        DRP_fig_HPD_zz.axes[-1].set_ylim([0,max_z])\n",
    "\n",
    "\n",
    "    # DEALING WITH EXTRA AXIS OUTSIDE CORNER PLOT\n",
    "    \n",
    "    if row==1 and column==0:\n",
    "        if not make_extra_plot:\n",
    "            i -= 1\n",
    "            make_extra_plot=True\n",
    "        else:\n",
    "            make_extra_plot=False\n",
    "\n",
    "            extra_title = 'Combined coverage for ('+POI_names[0]+','+POI_names[1]+')'\n",
    "            extra_title_size = 15\n",
    "            extra_legend_size = 10\n",
    "            extra_legend_loc = legend_loc\n",
    "\n",
    "            for fig_i, fig in enumerate(fig_list):\n",
    "                fig.axes[-1].set_xticks(x_tick_list[fig_i])\n",
    "                fig.axes[-1].set_xticklabels(x_tick_list[fig_i])\n",
    "                fig.axes[-1].tick_params(axis='x',labelsize=tick_size,pad=x_tick_pad)\n",
    "                fig.axes[-1].tick_params(axis='y',labelsize=tick_size,pad=y_tick_pad)\n",
    "                fig.axes[-1].set_xlabel(x_axis_list[fig_i], fontsize=label_size, labelpad=label_pad)\n",
    "                fig.axes[-1].set_ylabel(y_axis_list[fig_i], fontsize=label_size, labelpad=label_pad)\n",
    "                fig.axes[-1].set_title(extra_title, fontsize=extra_title_size)\n",
    "                \n",
    "           \n",
    "            # DRP_fig_pp.axes[-1].set_yticks(ticks_pp)\n",
    "            DRP_fig_pp.axes[-1].set_yticklabels(ticks_pp)\n",
    "            # DRP_fig_zz.axes[-1].set_yticks(ticks_zz)\n",
    "            DRP_fig_zz.axes[-1].set_yticklabels(ticks_zz)\n",
    "            if not HPD_residuals:\n",
    "                DRP_fig_HPD_pp.axes[-1].set_yticklabels(ticks_pp)\n",
    "                DRP_fig_HPD_zz.axes[-1].set_yticklabels(ticks_zz)\n",
    "    \n",
    "    elif row==1 and column==1:\n",
    "        extra_title_size = 15\n",
    "        extra_legend_size = 10\n",
    "        for fig_i, fig in enumerate(fig_list):\n",
    "            fig.axes[-1].legend(prop={'size': extra_legend_size}, loc = \"upper left\", bbox_to_anchor=extra_legend_loc)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc1226-d34d-4a4f-aeb3-97a6e341463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testfig = plt.figure(figsize = (12, 6))\n",
    "testfig.add_subplot(1,2,1)\n",
    "testfig.axes[0].plot([0,1],[0,1], color = (1,0.5,0), linestyle='--')\n",
    "testfig.axes[0].fill_between([0,1],[0,1],[0,0.5], label = 'yoop')\n",
    "testfig.axes[0].fill_between([0,1],[0,-1])\n",
    "testfig.axes[0].set_xlabel(\"Empirical $1-\\\\alpha$\", fontsize=10,labelpad=0)\n",
    "testfig.axes[0].set_xlabel(None)\n",
    "testfig.axes[0].set_ylabel(\"$\\mathrm{ECP}\\;/\\;\\Delta \\mathrm{ECP}$\", fontsize=10, labelpad=0)\n",
    "testfig.axes[0].tick_params(axis='both',labelsize=10,pad=1)\n",
    "testfig.axes[0].tick_params(axis='y',rotation=45, pad=-1)\n",
    "testfig.axes[0].legend(loc='upper left', bbox_to_anchor=(0,1.1))\n",
    "testfig.add_subplot(1,2,2)\n",
    "for rnd in range(which_truncation+1):\n",
    "    round = 'round_'+str(rnd)\n",
    "    # swyft.plot_pp(coverage_samples[round], eval(keys_2d[0].replace(' ',',')),ax = testfig.axes[1])\n",
    "    swyft.plot_pp(coverage_samples[round], keys_1d[0],ax = testfig.axes[1],diagonal_color='g',color=adjusted_colors[rnd])\n",
    "testfig.tight_layout(w_pad = -1)\n",
    "testfig.axes[0].set_yticks([0,0.2,0.4])\n",
    "testfig.axes[0].set_yticklabels([0,0.2,0.4])\n",
    "testfig.axes[0].yaxis.set_major_locator(plt.AutoLocator())\n",
    "testfig.axes[0].yaxis.set_major_formatter(plt.ScalarFormatter(None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f4742-9bfd-4b26-86ed-ea797f3ee575",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_title = extra_title\n",
    "single_title_size = 30\n",
    "single_label_size = 25\n",
    "single_tick_size = 20\n",
    "single_x_tick_pad = 5\n",
    "single_y_tick_pad = 1\n",
    "legend_size=15\n",
    "\n",
    "for ax in DRP_fig_pp.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_pp.axes[1].set_visible(True)\n",
    "DRP_fig_pp.axes[1].set_xticks([0.5,0.682,0.954])\n",
    "DRP_fig_pp.axes[1].set_xticklabels([0.5,0.68,0.95])\n",
    "DRP_fig_pp.axes[1].tick_params(axis='x',labelsize=single_tick_size,pad=single_x_tick_pad)\n",
    "DRP_fig_pp.axes[1].tick_params(axis='y',labelsize=single_tick_size,pad=single_y_tick_pad)\n",
    "DRP_fig_pp.axes[1].set_xlabel(x_axis_pp, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_pp.axes[1].set_ylabel(y_axis_pp, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_pp.axes[1].set_title(single_title, fontsize=single_title_size)\n",
    "DRP_fig_pp.axes[1].legend(prop={'size': legend_size})\n",
    "DRP_fig_pp.set_figheight(12*5)\n",
    "DRP_fig_pp.set_figwidth(12*5)\n",
    "DRP_fig_pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f2b1b-9310-414e-a5bf-84c0aa845d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_zz.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_zz.axes[1].set_visible(True)\n",
    "DRP_fig_zz.axes[1].set_xticks([1,2,3])\n",
    "DRP_fig_zz.axes[1].set_xticklabels([1,2,3])\n",
    "DRP_fig_zz.axes[1].set_yticks([1,2,3])\n",
    "DRP_fig_zz.axes[1].set_yticklabels([1,2,3])\n",
    "DRP_fig_zz.axes[1].tick_params(axis='x',labelsize=single_tick_size,pad=single_x_tick_pad)\n",
    "DRP_fig_zz.axes[1].tick_params(axis='y',labelsize=single_tick_size,pad=single_y_tick_pad)\n",
    "DRP_fig_zz.axes[1].set_xlabel(x_axis_zz, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_zz.axes[1].set_ylabel(y_axis_zz, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_zz.axes[1].set_title(single_title, fontsize=single_title_size)\n",
    "DRP_fig_zz.axes[1].legend(prop={'size': legend_size})\n",
    "DRP_fig_zz.set_figheight(12*5)\n",
    "DRP_fig_zz.set_figwidth(12*5)\n",
    "DRP_fig_zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f86c2-7695-44c7-89c7-9f12295993e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_rel.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_rel.axes[1].set_visible(True)\n",
    "DRP_fig_rel.axes[1].tick_params(axis='x',labelsize=single_tick_size,pad=single_x_tick_pad)\n",
    "DRP_fig_rel.axes[1].tick_params(axis='y',labelsize=single_tick_size,pad=single_y_tick_pad)\n",
    "DRP_fig_rel.axes[1].set_xlabel(x_axis_rel, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_rel.axes[1].set_ylabel(y_axis_rel, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_rel.axes[1].set_title(single_title, fontsize=single_title_size)\n",
    "DRP_fig_rel.axes[1].legend(prop={'size': legend_size})\n",
    "DRP_fig_rel.set_figheight(12*5)\n",
    "DRP_fig_rel.set_figwidth(12*5)\n",
    "DRP_fig_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60224cb-5598-4144-9bf9-8fb421f8d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_rel_zz.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_rel_zz.axes[1].set_visible(True)\n",
    "DRP_fig_rel_zz.axes[1].tick_params(axis='x',labelsize=single_tick_size,pad=single_x_tick_pad)\n",
    "DRP_fig_rel_zz.axes[1].tick_params(axis='y',labelsize=single_tick_size,pad=single_y_tick_pad)\n",
    "DRP_fig_rel_zz.axes[1].set_xlabel(x_axis_rel_zz, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_rel_zz.axes[1].set_ylabel(y_axis_rel_zz, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_rel_zz.axes[1].set_title(single_title, fontsize=single_title_size)\n",
    "DRP_fig_rel_zz.axes[1].legend(prop={'size': legend_size})\n",
    "DRP_fig_rel_zz.set_figheight(12*5)\n",
    "DRP_fig_rel_zz.set_figwidth(12*5)\n",
    "DRP_fig_rel_zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8be534-1af4-4668-9958-30d218efc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ax in DRP_fig_HPD_zz.axes:\n",
    "    ax.set_visible(False)\n",
    "DRP_fig_HPD_zz.axes[1].set_visible(True)\n",
    "DRP_fig_HPD_zz.axes[1].tick_params(axis='x',labelsize=single_tick_size,pad=single_x_tick_pad)\n",
    "DRP_fig_HPD_zz.axes[1].tick_params(axis='y',labelsize=single_tick_size,pad=single_y_tick_pad)\n",
    "DRP_fig_HPD_zz.axes[1].set_xlabel(x_axis_rel_zz, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_HPD_zz.axes[1].set_ylabel(y_axis_rel_zz, fontsize=single_label_size, labelpad=label_pad)\n",
    "DRP_fig_HPD_zz.axes[1].set_title(single_title, fontsize=single_title_size)\n",
    "DRP_fig_HPD_zz.axes[1].legend(prop={'size': legend_size})\n",
    "DRP_fig_HPD_zz.set_figheight(12*5)\n",
    "DRP_fig_HPD_zz.set_figwidth(12*5)\n",
    "DRP_fig_HPD_zz.axes[1].set_ylim([-0.75,0.75])\n",
    "DRP_fig_HPD_zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a5fc9-bf68-41a4-a485-17ab33742cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99caf2-be8c-4677-9155-0a824c975fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
